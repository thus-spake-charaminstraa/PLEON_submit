{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13060,
     "status": "ok",
     "timestamp": 1666354236457,
     "user": {
      "displayName": "차준혁",
      "userId": "06162925735462569720"
     },
     "user_tz": -540
    },
    "id": "JRWFodxlbfb8",
    "outputId": "5fa5c461-0d2b-490d-f537-1f5923652ad7",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/hyeokiki/anaconda3/lib/python3.9/site-packages (4.23.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/hyeokiki/anaconda3/lib/python3.9/site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/hyeokiki/anaconda3/lib/python3.9/site-packages (from transformers) (1.21.5)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/hyeokiki/anaconda3/lib/python3.9/site-packages (from transformers) (0.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /home/hyeokiki/anaconda3/lib/python3.9/site-packages (from transformers) (0.10.1)\n",
      "Requirement already satisfied: requests in /home/hyeokiki/anaconda3/lib/python3.9/site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/hyeokiki/anaconda3/lib/python3.9/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: filelock in /home/hyeokiki/anaconda3/lib/python3.9/site-packages (from transformers) (3.6.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/hyeokiki/anaconda3/lib/python3.9/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/hyeokiki/anaconda3/lib/python3.9/site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/hyeokiki/anaconda3/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/hyeokiki/anaconda3/lib/python3.9/site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/hyeokiki/anaconda3/lib/python3.9/site-packages (from requests->transformers) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/hyeokiki/anaconda3/lib/python3.9/site-packages (from requests->transformers) (2022.9.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/hyeokiki/anaconda3/lib/python3.9/site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/hyeokiki/anaconda3/lib/python3.9/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: pandas in /home/hyeokiki/anaconda3/lib/python3.9/site-packages (1.4.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/hyeokiki/anaconda3/lib/python3.9/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/hyeokiki/anaconda3/lib/python3.9/site-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /home/hyeokiki/anaconda3/lib/python3.9/site-packages (from pandas) (1.21.5)\n",
      "Requirement already satisfied: six>=1.5 in /home/hyeokiki/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Requirement already satisfied: sklearn in /home/hyeokiki/anaconda3/lib/python3.9/site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in /home/hyeokiki/anaconda3/lib/python3.9/site-packages (from sklearn) (1.0.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/hyeokiki/anaconda3/lib/python3.9/site-packages (from scikit-learn->sklearn) (2.2.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/hyeokiki/anaconda3/lib/python3.9/site-packages (from scikit-learn->sklearn) (1.1.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /home/hyeokiki/anaconda3/lib/python3.9/site-packages (from scikit-learn->sklearn) (1.9.1)\n",
      "Requirement already satisfied: numpy>=1.14.6 in /home/hyeokiki/anaconda3/lib/python3.9/site-packages (from scikit-learn->sklearn) (1.21.5)\n",
      "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu116\n",
      "Requirement already satisfied: torch in /home/hyeokiki/anaconda3/lib/python3.9/site-packages (1.12.1)\n",
      "Requirement already satisfied: torchvision in /home/hyeokiki/anaconda3/lib/python3.9/site-packages (0.13.1)\n",
      "Requirement already satisfied: torchaudio in /home/hyeokiki/anaconda3/lib/python3.9/site-packages (0.12.1)\n",
      "Requirement already satisfied: typing_extensions in /home/hyeokiki/anaconda3/lib/python3.9/site-packages (from torch) (4.3.0)\n",
      "Requirement already satisfied: numpy in /home/hyeokiki/anaconda3/lib/python3.9/site-packages (from torchvision) (1.21.5)\n",
      "Requirement already satisfied: requests in /home/hyeokiki/anaconda3/lib/python3.9/site-packages (from torchvision) (2.28.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/hyeokiki/anaconda3/lib/python3.9/site-packages (from torchvision) (9.2.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/hyeokiki/anaconda3/lib/python3.9/site-packages (from requests->torchvision) (2022.9.14)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/hyeokiki/anaconda3/lib/python3.9/site-packages (from requests->torchvision) (1.26.11)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/hyeokiki/anaconda3/lib/python3.9/site-packages (from requests->torchvision) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/hyeokiki/anaconda3/lib/python3.9/site-packages (from requests->torchvision) (3.3)\n",
      "Requirement already satisfied: tensorboard in /home/hyeokiki/anaconda3/lib/python3.9/site-packages (2.10.1)\n",
      "Requirement already satisfied: tensorboardx in /home/hyeokiki/anaconda3/lib/python3.9/site-packages (2.5.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/hyeokiki/anaconda3/lib/python3.9/site-packages (from tensorboard) (2.0.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/hyeokiki/anaconda3/lib/python3.9/site-packages (from tensorboard) (3.3.4)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/hyeokiki/anaconda3/lib/python3.9/site-packages (from tensorboard) (2.13.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/hyeokiki/anaconda3/lib/python3.9/site-packages (from tensorboard) (2.28.1)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /home/hyeokiki/anaconda3/lib/python3.9/site-packages (from tensorboard) (1.21.5)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /home/hyeokiki/anaconda3/lib/python3.9/site-packages (from tensorboard) (1.50.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /home/hyeokiki/anaconda3/lib/python3.9/site-packages (from tensorboard) (3.19.6)\n",
      "Requirement already satisfied: absl-py>=0.4 in /home/hyeokiki/anaconda3/lib/python3.9/site-packages (from tensorboard) (1.3.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /home/hyeokiki/anaconda3/lib/python3.9/site-packages (from tensorboard) (0.37.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/hyeokiki/anaconda3/lib/python3.9/site-packages (from tensorboard) (0.4.6)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/hyeokiki/anaconda3/lib/python3.9/site-packages (from tensorboard) (63.4.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/hyeokiki/anaconda3/lib/python3.9/site-packages (from tensorboard) (1.8.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/hyeokiki/anaconda3/lib/python3.9/site-packages (from tensorboard) (0.6.1)\n",
      "Requirement already satisfied: six>=1.9.0 in /home/hyeokiki/anaconda3/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard) (1.16.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/hyeokiki/anaconda3/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard) (4.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/hyeokiki/anaconda3/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/hyeokiki/anaconda3/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard) (5.2.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/hyeokiki/anaconda3/lib/python3.9/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/hyeokiki/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/hyeokiki/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/hyeokiki/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/hyeokiki/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard) (2022.9.14)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/hyeokiki/anaconda3/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/hyeokiki/anaconda3/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "# all the imports\n",
    "!pip install transformers\n",
    "!pip install pandas\n",
    "!pip install sklearn\n",
    "!pip3 install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu116\n",
    "!pip3 install tensorboard tensorboardx\n",
    "\n",
    "import glob\n",
    "import logging\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import re\n",
    "import shutil\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader, Dataset, RandomSampler, SequentialSampler\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from tqdm.notebook import tqdm, trange\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from transformers import (\n",
    "    MODEL_WITH_LM_HEAD_MAPPING,\n",
    "    WEIGHTS_NAME,\n",
    "    AdamW,\n",
    "    AutoConfig,\n",
    "    PreTrainedModel,\n",
    "    PreTrainedTokenizer,\n",
    "    get_linear_schedule_with_warmup,\n",
    ")\n",
    "\n",
    "\n",
    "try:\n",
    "    from torch.utils.tensorboard import SummaryWriter\n",
    "except ImportError:\n",
    "    from tensorboardX import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "executionInfo": {
     "elapsed": 2275,
     "status": "ok",
     "timestamp": 1666354238725,
     "user": {
      "displayName": "차준혁",
      "userId": "06162925735462569720"
     },
     "user_tz": -540
    },
    "id": "SU2u0lZkfdA8",
    "outputId": "4768c5c6-b972-42b1-9ba6-a78daffd12de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyarrow in /home/hyeokiki/anaconda3/lib/python3.9/site-packages (9.0.0)\r\n",
      "Requirement already satisfied: numpy>=1.16.6 in /home/hyeokiki/anaconda3/lib/python3.9/site-packages (from pyarrow) (1.21.5)\r\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['요즘 동물들을 유기 하는 애들도 참 문제야 ㅠㅠ', '동물들을 유기 하는 사람이...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['강릉에  어떤 호텔에서 오징어 게임 한데', '오징어게임? 설마 죽는 거 아이제...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['이렇게 너와 내가 국제 관계를 트는구나', '그래 해외에 친구가 있는 것도 나쁘...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['너는 전철 자주 타고 다니는 편이야?', '예전엔 많이 타고 다녔는데 요즘 통 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['귀멸의 칼날 봤니?', '응 당연 봤지', '안 볼 수가 없지', '키키 극장판...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128650</th>\n",
       "      <td>['스파티필룸 왈리시(스파티필룸)', '흰색의 불염포와 짙은 녹색의 윤기 있는 잎이...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128651</th>\n",
       "      <td>['싱고니움', '싱고니움은 대표적인 잎보기 식물로 연두색, 흰색, 분홍색 등의 잎...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128652</th>\n",
       "      <td>['마삭줄 / 오색마삭줄 / 황금마삭줄', '우리나라 남부지방에서 주로 자생하며 상...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128653</th>\n",
       "      <td>['튤립', '터키가 원산지인 튤립은 가을에 심는 구근식물로 실내에서는 겨울부터 봄...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128654</th>\n",
       "      <td>['멕시코소철', '멕시코소철은 상록교목으로 일반 소철과 달리 잎이 넓고 잎 표면에...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>128655 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     data\n",
       "0       ['요즘 동물들을 유기 하는 애들도 참 문제야 ㅠㅠ', '동물들을 유기 하는 사람이...\n",
       "1       ['강릉에  어떤 호텔에서 오징어 게임 한데', '오징어게임? 설마 죽는 거 아이제...\n",
       "2       ['이렇게 너와 내가 국제 관계를 트는구나', '그래 해외에 친구가 있는 것도 나쁘...\n",
       "3       ['너는 전철 자주 타고 다니는 편이야?', '예전엔 많이 타고 다녔는데 요즘 통 ...\n",
       "4       ['귀멸의 칼날 봤니?', '응 당연 봤지', '안 볼 수가 없지', '키키 극장판...\n",
       "...                                                   ...\n",
       "128650  ['스파티필룸 왈리시(스파티필룸)', '흰색의 불염포와 짙은 녹색의 윤기 있는 잎이...\n",
       "128651  ['싱고니움', '싱고니움은 대표적인 잎보기 식물로 연두색, 흰색, 분홍색 등의 잎...\n",
       "128652  ['마삭줄 / 오색마삭줄 / 황금마삭줄', '우리나라 남부지방에서 주로 자생하며 상...\n",
       "128653  ['튤립', '터키가 원산지인 튤립은 가을에 심는 구근식물로 실내에서는 겨울부터 봄...\n",
       "128654  ['멕시코소철', '멕시코소철은 상록교목으로 일반 소철과 달리 잎이 넓고 잎 표면에...\n",
       "\n",
       "[128655 rows x 1 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install pyarrow\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# feather_path = '/content/drive/Othercomputers/MacBookPro/chatbot/0926_학습용_일상대화_감성대화.feather'\n",
    "feather_path = '/home/hyeokiki/Desktop/ko_dialogpt/1012_학습용_일상대화_감성대화_대화체관리가이드.feather'\n",
    "f = pd.read_feather(feather_path)\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "9kMvzIFikM4k"
   },
   "outputs": [],
   "source": [
    "# new_df = pd.DataFrame(columns=['data'])\n",
    "\n",
    "# ko_list = []\n",
    "# for i in range(0, len(f)):\n",
    "#   s = f.iloc[i]\n",
    "#   s = s.apply(lambda x: eval(x))\n",
    "#   for j in range(len(s[0])):\n",
    "#     s[0][j] = s[0][j].strip('\\n')\n",
    "#   new_df.loc[len(new_df)] = str(s[0])\n",
    "# new_df.to_feather('test.feather')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "9Rga-4Ajnj58"
   },
   "outputs": [],
   "source": [
    "# new_df.to_feather('/content/drive/Othercomputers/MacBookPro/chatbot/일상대화.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4308,
     "status": "ok",
     "timestamp": 1666354243027,
     "user": {
      "displayName": "차준혁",
      "userId": "06162925735462569720"
     },
     "user_tz": -540
    },
    "id": "jWHLZhT0dTgt",
    "outputId": "1e3f5644-e184-40c6-9f99-58c3600a373f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    128655.000000\n",
       "mean         12.953923\n",
       "std           7.062172\n",
       "min           1.000000\n",
       "25%           6.000000\n",
       "50%          12.000000\n",
       "75%          17.000000\n",
       "max         108.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.apply(lambda x : len(eval(x[0])), axis = 1).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1666354243027,
     "user": {
      "displayName": "차준혁",
      "userId": "06162925735462569720"
     },
     "user_tz": -540
    },
    "id": "bB9aWEO1cu0A",
    "outputId": "ed7401ea-dbb9-46a6-e04b-e29ae77c3150",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['코로나만 어떻게 해결된다면 사회적 이슈가 잦아질텐데 말이야...',\n",
       "  '거기다가 변이 바이러스까지 겹쳐서 걱정이다...',\n",
       "  '그게 난 정말 의문이야 ㅠㅠ',\n",
       "  '백신이 아직까지는 큰 효과를 보지는 못하는 거 같아...',\n",
       "  '그런데 백신을 그렇게 많은 사람들이 맞고 있는데 왜 더 늘어날까?',\n",
       "  '휴 추석이 끝나고 1주일 동안은 엄청 늘어날 거라고 하더니 그래도 생각보단 괜찮네 아직',\n",
       "  '코로나가 제일 심각한 문제긴 하지 우리나라 뿐만 아니라 전 세계적으로 문제가 있는 거라',\n",
       "  '며칠 전에 3200명이란 어마어마한 확진자가 발생했잖아',\n",
       "  '아무래도 가장 큰 건 코로나 아닐까?',\n",
       "  '요즘 사회적 이슈들은 뭐가 있을까?',\n",
       "  '다 벌 받을 거야 나쁜 사람들 ㅠ',\n",
       "  '**이 알레르기 있어서 만지지도 못하고 안타깝다 정말 귀여운데',\n",
       "  '고양이도 소중한 생명인데 길거리에 버려진 고양이들 보면 너무 안타까워',\n",
       "  '우리 원룸 주변에 보면 아직도 길고양이들 돌아다니고 하더라고 ㅠㅠ',\n",
       "  '그치 동물들도 요즘 사회적 이슈고 요즘 또 이슈화 있는 사건이 많더라고',\n",
       "  '동물들을 유기 하는 사람이 아직도 있어?',\n",
       "  '요즘 동물들을 유기 하는 애들도 참 문제야 ㅠㅠ'],\n",
       " ['다음 대통령은 꼭 코로나를 잡진 못하더라도 완만히 넘길 수 있는 대통령이 나왔으면 좋겠어!',\n",
       "  '코로나만 어떻게 해결된다면 사회적 이슈가 잦아질텐데 말이야...',\n",
       "  '거기다가 변이 바이러스까지 겹쳐서 걱정이다...',\n",
       "  '그게 난 정말 의문이야 ㅠㅠ',\n",
       "  '백신이 아직까지는 큰 효과를 보지는 못하는 거 같아...',\n",
       "  '그런데 백신을 그렇게 많은 사람들이 맞고 있는데 왜 더 늘어날까?',\n",
       "  '휴 추석이 끝나고 1주일 동안은 엄청 늘어날 거라고 하더니 그래도 생각보단 괜찮네 아직',\n",
       "  '코로나가 제일 심각한 문제긴 하지 우리나라 뿐만 아니라 전 세계적으로 문제가 있는 거라',\n",
       "  '며칠 전에 3200명이란 어마어마한 확진자가 발생했잖아',\n",
       "  '아무래도 가장 큰 건 코로나 아닐까?',\n",
       "  '요즘 사회적 이슈들은 뭐가 있을까?',\n",
       "  '다 벌 받을 거야 나쁜 사람들 ㅠ',\n",
       "  '**이 알레르기 있어서 만지지도 못하고 안타깝다 정말 귀여운데',\n",
       "  '고양이도 소중한 생명인데 길거리에 버려진 고양이들 보면 너무 안타까워',\n",
       "  '우리 원룸 주변에 보면 아직도 길고양이들 돌아다니고 하더라고 ㅠㅠ',\n",
       "  '그치 동물들도 요즘 사회적 이슈고 요즘 또 이슈화 있는 사건이 많더라고',\n",
       "  '동물들을 유기 하는 사람이 아직도 있어?'],\n",
       " ['다음 대통령은 과연 누가 될까? 궁금하다',\n",
       "  '다음 대통령은 꼭 코로나를 잡진 못하더라도 완만히 넘길 수 있는 대통령이 나왔으면 좋겠어!',\n",
       "  '코로나만 어떻게 해결된다면 사회적 이슈가 잦아질텐데 말이야...',\n",
       "  '거기다가 변이 바이러스까지 겹쳐서 걱정이다...',\n",
       "  '그게 난 정말 의문이야 ㅠㅠ',\n",
       "  '백신이 아직까지는 큰 효과를 보지는 못하는 거 같아...',\n",
       "  '그런데 백신을 그렇게 많은 사람들이 맞고 있는데 왜 더 늘어날까?',\n",
       "  '휴 추석이 끝나고 1주일 동안은 엄청 늘어날 거라고 하더니 그래도 생각보단 괜찮네 아직',\n",
       "  '코로나가 제일 심각한 문제긴 하지 우리나라 뿐만 아니라 전 세계적으로 문제가 있는 거라',\n",
       "  '며칠 전에 3200명이란 어마어마한 확진자가 발생했잖아',\n",
       "  '아무래도 가장 큰 건 코로나 아닐까?',\n",
       "  '요즘 사회적 이슈들은 뭐가 있을까?',\n",
       "  '다 벌 받을 거야 나쁜 사람들 ㅠ',\n",
       "  '**이 알레르기 있어서 만지지도 못하고 안타깝다 정말 귀여운데',\n",
       "  '고양이도 소중한 생명인데 길거리에 버려진 고양이들 보면 너무 안타까워',\n",
       "  '우리 원룸 주변에 보면 아직도 길고양이들 돌아다니고 하더라고 ㅠㅠ',\n",
       "  '그치 동물들도 요즘 사회적 이슈고 요즘 또 이슈화 있는 사건이 많더라고'],\n",
       " ['내가 생각했을 때 대통령이 제일 중요한 인물이기 때문에 좋은 사람이 되기를 바래야지 ㅠㅠ',\n",
       "  '다음 대통령은 과연 누가 될까? 궁금하다',\n",
       "  '다음 대통령은 꼭 코로나를 잡진 못하더라도 완만히 넘길 수 있는 대통령이 나왔으면 좋겠어!',\n",
       "  '코로나만 어떻게 해결된다면 사회적 이슈가 잦아질텐데 말이야...',\n",
       "  '거기다가 변이 바이러스까지 겹쳐서 걱정이다...',\n",
       "  '그게 난 정말 의문이야 ㅠㅠ',\n",
       "  '백신이 아직까지는 큰 효과를 보지는 못하는 거 같아...',\n",
       "  '그런데 백신을 그렇게 많은 사람들이 맞고 있는데 왜 더 늘어날까?',\n",
       "  '휴 추석이 끝나고 1주일 동안은 엄청 늘어날 거라고 하더니 그래도 생각보단 괜찮네 아직',\n",
       "  '코로나가 제일 심각한 문제긴 하지 우리나라 뿐만 아니라 전 세계적으로 문제가 있는 거라',\n",
       "  '며칠 전에 3200명이란 어마어마한 확진자가 발생했잖아',\n",
       "  '아무래도 가장 큰 건 코로나 아닐까?',\n",
       "  '요즘 사회적 이슈들은 뭐가 있을까?',\n",
       "  '다 벌 받을 거야 나쁜 사람들 ㅠ',\n",
       "  '**이 알레르기 있어서 만지지도 못하고 안타깝다 정말 귀여운데',\n",
       "  '고양이도 소중한 생명인데 길거리에 버려진 고양이들 보면 너무 안타까워',\n",
       "  '우리 원룸 주변에 보면 아직도 길고양이들 돌아다니고 하더라고 ㅠㅠ'],\n",
       " ['그치 우리한테는 직접적으로까진 아니어도 분명 영향을 줄 거야 대통령이라는 사람은',\n",
       "  '내가 생각했을 때 대통령이 제일 중요한 인물이기 때문에 좋은 사람이 되기를 바래야지 ㅠㅠ',\n",
       "  '다음 대통령은 과연 누가 될까? 궁금하다',\n",
       "  '다음 대통령은 꼭 코로나를 잡진 못하더라도 완만히 넘길 수 있는 대통령이 나왔으면 좋겠어!',\n",
       "  '코로나만 어떻게 해결된다면 사회적 이슈가 잦아질텐데 말이야...',\n",
       "  '거기다가 변이 바이러스까지 겹쳐서 걱정이다...',\n",
       "  '그게 난 정말 의문이야 ㅠㅠ',\n",
       "  '백신이 아직까지는 큰 효과를 보지는 못하는 거 같아...',\n",
       "  '그런데 백신을 그렇게 많은 사람들이 맞고 있는데 왜 더 늘어날까?',\n",
       "  '휴 추석이 끝나고 1주일 동안은 엄청 늘어날 거라고 하더니 그래도 생각보단 괜찮네 아직',\n",
       "  '코로나가 제일 심각한 문제긴 하지 우리나라 뿐만 아니라 전 세계적으로 문제가 있는 거라',\n",
       "  '며칠 전에 3200명이란 어마어마한 확진자가 발생했잖아',\n",
       "  '아무래도 가장 큰 건 코로나 아닐까?',\n",
       "  '요즘 사회적 이슈들은 뭐가 있을까?',\n",
       "  '다 벌 받을 거야 나쁜 사람들 ㅠ',\n",
       "  '**이 알레르기 있어서 만지지도 못하고 안타깝다 정말 귀여운데',\n",
       "  '고양이도 소중한 생명인데 길거리에 버려진 고양이들 보면 너무 안타까워'],\n",
       " ['요번에 정말 평등한 사회를 만들어주는 대통령이 나왔으면 좋겠어',\n",
       "  '그치 우리한테는 직접적으로까진 아니어도 분명 영향을 줄 거야 대통령이라는 사람은',\n",
       "  '내가 생각했을 때 대통령이 제일 중요한 인물이기 때문에 좋은 사람이 되기를 바래야지 ㅠㅠ',\n",
       "  '다음 대통령은 과연 누가 될까? 궁금하다',\n",
       "  '다음 대통령은 꼭 코로나를 잡진 못하더라도 완만히 넘길 수 있는 대통령이 나왔으면 좋겠어!',\n",
       "  '코로나만 어떻게 해결된다면 사회적 이슈가 잦아질텐데 말이야...',\n",
       "  '거기다가 변이 바이러스까지 겹쳐서 걱정이다...',\n",
       "  '그게 난 정말 의문이야 ㅠㅠ',\n",
       "  '백신이 아직까지는 큰 효과를 보지는 못하는 거 같아...',\n",
       "  '그런데 백신을 그렇게 많은 사람들이 맞고 있는데 왜 더 늘어날까?',\n",
       "  '휴 추석이 끝나고 1주일 동안은 엄청 늘어날 거라고 하더니 그래도 생각보단 괜찮네 아직',\n",
       "  '코로나가 제일 심각한 문제긴 하지 우리나라 뿐만 아니라 전 세계적으로 문제가 있는 거라',\n",
       "  '며칠 전에 3200명이란 어마어마한 확진자가 발생했잖아',\n",
       "  '아무래도 가장 큰 건 코로나 아닐까?',\n",
       "  '요즘 사회적 이슈들은 뭐가 있을까?',\n",
       "  '다 벌 받을 거야 나쁜 사람들 ㅠ',\n",
       "  '**이 알레르기 있어서 만지지도 못하고 안타깝다 정말 귀여운데'],\n",
       " ['솔직히 평등한 사회가 될 수는 없어',\n",
       "  '요번에 정말 평등한 사회를 만들어주는 대통령이 나왔으면 좋겠어',\n",
       "  '그치 우리한테는 직접적으로까진 아니어도 분명 영향을 줄 거야 대통령이라는 사람은',\n",
       "  '내가 생각했을 때 대통령이 제일 중요한 인물이기 때문에 좋은 사람이 되기를 바래야지 ㅠㅠ',\n",
       "  '다음 대통령은 과연 누가 될까? 궁금하다',\n",
       "  '다음 대통령은 꼭 코로나를 잡진 못하더라도 완만히 넘길 수 있는 대통령이 나왔으면 좋겠어!',\n",
       "  '코로나만 어떻게 해결된다면 사회적 이슈가 잦아질텐데 말이야...',\n",
       "  '거기다가 변이 바이러스까지 겹쳐서 걱정이다...',\n",
       "  '그게 난 정말 의문이야 ㅠㅠ',\n",
       "  '백신이 아직까지는 큰 효과를 보지는 못하는 거 같아...',\n",
       "  '그런데 백신을 그렇게 많은 사람들이 맞고 있는데 왜 더 늘어날까?',\n",
       "  '휴 추석이 끝나고 1주일 동안은 엄청 늘어날 거라고 하더니 그래도 생각보단 괜찮네 아직',\n",
       "  '코로나가 제일 심각한 문제긴 하지 우리나라 뿐만 아니라 전 세계적으로 문제가 있는 거라',\n",
       "  '며칠 전에 3200명이란 어마어마한 확진자가 발생했잖아',\n",
       "  '아무래도 가장 큰 건 코로나 아닐까?',\n",
       "  '요즘 사회적 이슈들은 뭐가 있을까?',\n",
       "  '다 벌 받을 거야 나쁜 사람들 ㅠ'],\n",
       " ['그래도 평등하게 만들어줄 수 있는 사람이 우리에게 필요한 거지',\n",
       "  '솔직히 평등한 사회가 될 수는 없어',\n",
       "  '요번에 정말 평등한 사회를 만들어주는 대통령이 나왔으면 좋겠어',\n",
       "  '그치 우리한테는 직접적으로까진 아니어도 분명 영향을 줄 거야 대통령이라는 사람은',\n",
       "  '내가 생각했을 때 대통령이 제일 중요한 인물이기 때문에 좋은 사람이 되기를 바래야지 ㅠㅠ',\n",
       "  '다음 대통령은 과연 누가 될까? 궁금하다',\n",
       "  '다음 대통령은 꼭 코로나를 잡진 못하더라도 완만히 넘길 수 있는 대통령이 나왔으면 좋겠어!',\n",
       "  '코로나만 어떻게 해결된다면 사회적 이슈가 잦아질텐데 말이야...',\n",
       "  '거기다가 변이 바이러스까지 겹쳐서 걱정이다...',\n",
       "  '그게 난 정말 의문이야 ㅠㅠ',\n",
       "  '백신이 아직까지는 큰 효과를 보지는 못하는 거 같아...',\n",
       "  '그런데 백신을 그렇게 많은 사람들이 맞고 있는데 왜 더 늘어날까?',\n",
       "  '휴 추석이 끝나고 1주일 동안은 엄청 늘어날 거라고 하더니 그래도 생각보단 괜찮네 아직',\n",
       "  '코로나가 제일 심각한 문제긴 하지 우리나라 뿐만 아니라 전 세계적으로 문제가 있는 거라',\n",
       "  '며칠 전에 3200명이란 어마어마한 확진자가 발생했잖아',\n",
       "  '아무래도 가장 큰 건 코로나 아닐까?',\n",
       "  '요즘 사회적 이슈들은 뭐가 있을까?'],\n",
       " ['평등한 사회도 중요한 요소긴 하지.',\n",
       "  '그래도 평등하게 만들어줄 수 있는 사람이 우리에게 필요한 거지',\n",
       "  '솔직히 평등한 사회가 될 수는 없어',\n",
       "  '요번에 정말 평등한 사회를 만들어주는 대통령이 나왔으면 좋겠어',\n",
       "  '그치 우리한테는 직접적으로까진 아니어도 분명 영향을 줄 거야 대통령이라는 사람은',\n",
       "  '내가 생각했을 때 대통령이 제일 중요한 인물이기 때문에 좋은 사람이 되기를 바래야지 ㅠㅠ',\n",
       "  '다음 대통령은 과연 누가 될까? 궁금하다',\n",
       "  '다음 대통령은 꼭 코로나를 잡진 못하더라도 완만히 넘길 수 있는 대통령이 나왔으면 좋겠어!',\n",
       "  '코로나만 어떻게 해결된다면 사회적 이슈가 잦아질텐데 말이야...',\n",
       "  '거기다가 변이 바이러스까지 겹쳐서 걱정이다...',\n",
       "  '그게 난 정말 의문이야 ㅠㅠ',\n",
       "  '백신이 아직까지는 큰 효과를 보지는 못하는 거 같아...',\n",
       "  '그런데 백신을 그렇게 많은 사람들이 맞고 있는데 왜 더 늘어날까?',\n",
       "  '휴 추석이 끝나고 1주일 동안은 엄청 늘어날 거라고 하더니 그래도 생각보단 괜찮네 아직',\n",
       "  '코로나가 제일 심각한 문제긴 하지 우리나라 뿐만 아니라 전 세계적으로 문제가 있는 거라',\n",
       "  '며칠 전에 3200명이란 어마어마한 확진자가 발생했잖아',\n",
       "  '아무래도 가장 큰 건 코로나 아닐까?'],\n",
       " ['빨리 모두가 행복한 나날이 왔음 좋겠다',\n",
       "  '평등한 사회도 중요한 요소긴 하지.',\n",
       "  '그래도 평등하게 만들어줄 수 있는 사람이 우리에게 필요한 거지',\n",
       "  '솔직히 평등한 사회가 될 수는 없어',\n",
       "  '요번에 정말 평등한 사회를 만들어주는 대통령이 나왔으면 좋겠어',\n",
       "  '그치 우리한테는 직접적으로까진 아니어도 분명 영향을 줄 거야 대통령이라는 사람은',\n",
       "  '내가 생각했을 때 대통령이 제일 중요한 인물이기 때문에 좋은 사람이 되기를 바래야지 ㅠㅠ',\n",
       "  '다음 대통령은 과연 누가 될까? 궁금하다',\n",
       "  '다음 대통령은 꼭 코로나를 잡진 못하더라도 완만히 넘길 수 있는 대통령이 나왔으면 좋겠어!',\n",
       "  '코로나만 어떻게 해결된다면 사회적 이슈가 잦아질텐데 말이야...',\n",
       "  '거기다가 변이 바이러스까지 겹쳐서 걱정이다...',\n",
       "  '그게 난 정말 의문이야 ㅠㅠ',\n",
       "  '백신이 아직까지는 큰 효과를 보지는 못하는 거 같아...',\n",
       "  '그런데 백신을 그렇게 많은 사람들이 맞고 있는데 왜 더 늘어날까?',\n",
       "  '휴 추석이 끝나고 1주일 동안은 엄청 늘어날 거라고 하더니 그래도 생각보단 괜찮네 아직',\n",
       "  '코로나가 제일 심각한 문제긴 하지 우리나라 뿐만 아니라 전 세계적으로 문제가 있는 거라',\n",
       "  '며칠 전에 3200명이란 어마어마한 확진자가 발생했잖아']]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "\n",
    "# WINDOW = 7\n",
    "WINDOW = 17\n",
    "\n",
    "train_data = []\n",
    "\n",
    "def gen_context(data):\n",
    "  # data = eval(f.iloc[0][0])\n",
    "  \n",
    "  for i in range(len(data)) :\n",
    "    # print(data[i])\n",
    "    context = data[i + 1 - WINDOW: i + 1][::-1]\n",
    "    if len(context) != WINDOW : continue\n",
    "    # print(context)\n",
    "    train_data.append(context)\n",
    "\n",
    "gen_context(eval(f.iloc[0][0]))\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7301,
     "status": "ok",
     "timestamp": 1666354250326,
     "user": {
      "displayName": "차준혁",
      "userId": "06162925735462569720"
     },
     "user_tz": -540
    },
    "id": "pSO4g-ujb0yF",
    "outputId": "3de73865-079f-42cb-ef05-85907bd5286e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         None\n",
       "1         None\n",
       "2         None\n",
       "3         None\n",
       "4         None\n",
       "          ... \n",
       "128650    None\n",
       "128651    None\n",
       "128652    None\n",
       "128653    None\n",
       "128654    None\n",
       "Length: 128655, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.apply(lambda x : gen_context(eval(x[0])), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1666354250327,
     "user": {
      "displayName": "차준혁",
      "userId": "06162925735462569720"
     },
     "user_tz": -540
    },
    "id": "okRJquaIjVY0",
    "outputId": "e907dace-7959-4e39-de2e-8fdcdea51edc",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>response</th>\n",
       "      <th>context</th>\n",
       "      <th>context/0</th>\n",
       "      <th>context/1</th>\n",
       "      <th>context/2</th>\n",
       "      <th>context/3</th>\n",
       "      <th>context/4</th>\n",
       "      <th>context/5</th>\n",
       "      <th>context/6</th>\n",
       "      <th>context/7</th>\n",
       "      <th>context/8</th>\n",
       "      <th>context/9</th>\n",
       "      <th>context/10</th>\n",
       "      <th>context/11</th>\n",
       "      <th>context/12</th>\n",
       "      <th>context/13</th>\n",
       "      <th>context/14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>코로나만 어떻게 해결된다면 사회적 이슈가 잦아질텐데 말이야...</td>\n",
       "      <td>거기다가 변이 바이러스까지 겹쳐서 걱정이다...</td>\n",
       "      <td>그게 난 정말 의문이야 ㅠㅠ</td>\n",
       "      <td>백신이 아직까지는 큰 효과를 보지는 못하는 거 같아...</td>\n",
       "      <td>그런데 백신을 그렇게 많은 사람들이 맞고 있는데 왜 더 늘어날까?</td>\n",
       "      <td>휴 추석이 끝나고 1주일 동안은 엄청 늘어날 거라고 하더니 그래도 생각보단 괜찮네 아직</td>\n",
       "      <td>코로나가 제일 심각한 문제긴 하지 우리나라 뿐만 아니라 전 세계적으로 문제가 있는 거라</td>\n",
       "      <td>며칠 전에 3200명이란 어마어마한 확진자가 발생했잖아</td>\n",
       "      <td>아무래도 가장 큰 건 코로나 아닐까?</td>\n",
       "      <td>요즘 사회적 이슈들은 뭐가 있을까?</td>\n",
       "      <td>다 벌 받을 거야 나쁜 사람들 ㅠ</td>\n",
       "      <td>**이 알레르기 있어서 만지지도 못하고 안타깝다 정말 귀여운데</td>\n",
       "      <td>고양이도 소중한 생명인데 길거리에 버려진 고양이들 보면 너무 안타까워</td>\n",
       "      <td>우리 원룸 주변에 보면 아직도 길고양이들 돌아다니고 하더라고 ㅠㅠ</td>\n",
       "      <td>그치 동물들도 요즘 사회적 이슈고 요즘 또 이슈화 있는 사건이 많더라고</td>\n",
       "      <td>동물들을 유기 하는 사람이 아직도 있어?</td>\n",
       "      <td>요즘 동물들을 유기 하는 애들도 참 문제야 ㅠㅠ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>다음 대통령은 꼭 코로나를 잡진 못하더라도 완만히 넘길 수 있는 대통령이 나왔으면 ...</td>\n",
       "      <td>코로나만 어떻게 해결된다면 사회적 이슈가 잦아질텐데 말이야...</td>\n",
       "      <td>거기다가 변이 바이러스까지 겹쳐서 걱정이다...</td>\n",
       "      <td>그게 난 정말 의문이야 ㅠㅠ</td>\n",
       "      <td>백신이 아직까지는 큰 효과를 보지는 못하는 거 같아...</td>\n",
       "      <td>그런데 백신을 그렇게 많은 사람들이 맞고 있는데 왜 더 늘어날까?</td>\n",
       "      <td>휴 추석이 끝나고 1주일 동안은 엄청 늘어날 거라고 하더니 그래도 생각보단 괜찮네 아직</td>\n",
       "      <td>코로나가 제일 심각한 문제긴 하지 우리나라 뿐만 아니라 전 세계적으로 문제가 있는 거라</td>\n",
       "      <td>며칠 전에 3200명이란 어마어마한 확진자가 발생했잖아</td>\n",
       "      <td>아무래도 가장 큰 건 코로나 아닐까?</td>\n",
       "      <td>요즘 사회적 이슈들은 뭐가 있을까?</td>\n",
       "      <td>다 벌 받을 거야 나쁜 사람들 ㅠ</td>\n",
       "      <td>**이 알레르기 있어서 만지지도 못하고 안타깝다 정말 귀여운데</td>\n",
       "      <td>고양이도 소중한 생명인데 길거리에 버려진 고양이들 보면 너무 안타까워</td>\n",
       "      <td>우리 원룸 주변에 보면 아직도 길고양이들 돌아다니고 하더라고 ㅠㅠ</td>\n",
       "      <td>그치 동물들도 요즘 사회적 이슈고 요즘 또 이슈화 있는 사건이 많더라고</td>\n",
       "      <td>동물들을 유기 하는 사람이 아직도 있어?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>다음 대통령은 과연 누가 될까? 궁금하다</td>\n",
       "      <td>다음 대통령은 꼭 코로나를 잡진 못하더라도 완만히 넘길 수 있는 대통령이 나왔으면 ...</td>\n",
       "      <td>코로나만 어떻게 해결된다면 사회적 이슈가 잦아질텐데 말이야...</td>\n",
       "      <td>거기다가 변이 바이러스까지 겹쳐서 걱정이다...</td>\n",
       "      <td>그게 난 정말 의문이야 ㅠㅠ</td>\n",
       "      <td>백신이 아직까지는 큰 효과를 보지는 못하는 거 같아...</td>\n",
       "      <td>그런데 백신을 그렇게 많은 사람들이 맞고 있는데 왜 더 늘어날까?</td>\n",
       "      <td>휴 추석이 끝나고 1주일 동안은 엄청 늘어날 거라고 하더니 그래도 생각보단 괜찮네 아직</td>\n",
       "      <td>코로나가 제일 심각한 문제긴 하지 우리나라 뿐만 아니라 전 세계적으로 문제가 있는 거라</td>\n",
       "      <td>며칠 전에 3200명이란 어마어마한 확진자가 발생했잖아</td>\n",
       "      <td>아무래도 가장 큰 건 코로나 아닐까?</td>\n",
       "      <td>요즘 사회적 이슈들은 뭐가 있을까?</td>\n",
       "      <td>다 벌 받을 거야 나쁜 사람들 ㅠ</td>\n",
       "      <td>**이 알레르기 있어서 만지지도 못하고 안타깝다 정말 귀여운데</td>\n",
       "      <td>고양이도 소중한 생명인데 길거리에 버려진 고양이들 보면 너무 안타까워</td>\n",
       "      <td>우리 원룸 주변에 보면 아직도 길고양이들 돌아다니고 하더라고 ㅠㅠ</td>\n",
       "      <td>그치 동물들도 요즘 사회적 이슈고 요즘 또 이슈화 있는 사건이 많더라고</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>내가 생각했을 때 대통령이 제일 중요한 인물이기 때문에 좋은 사람이 되기를 바래야지 ㅠㅠ</td>\n",
       "      <td>다음 대통령은 과연 누가 될까? 궁금하다</td>\n",
       "      <td>다음 대통령은 꼭 코로나를 잡진 못하더라도 완만히 넘길 수 있는 대통령이 나왔으면 ...</td>\n",
       "      <td>코로나만 어떻게 해결된다면 사회적 이슈가 잦아질텐데 말이야...</td>\n",
       "      <td>거기다가 변이 바이러스까지 겹쳐서 걱정이다...</td>\n",
       "      <td>그게 난 정말 의문이야 ㅠㅠ</td>\n",
       "      <td>백신이 아직까지는 큰 효과를 보지는 못하는 거 같아...</td>\n",
       "      <td>그런데 백신을 그렇게 많은 사람들이 맞고 있는데 왜 더 늘어날까?</td>\n",
       "      <td>휴 추석이 끝나고 1주일 동안은 엄청 늘어날 거라고 하더니 그래도 생각보단 괜찮네 아직</td>\n",
       "      <td>코로나가 제일 심각한 문제긴 하지 우리나라 뿐만 아니라 전 세계적으로 문제가 있는 거라</td>\n",
       "      <td>며칠 전에 3200명이란 어마어마한 확진자가 발생했잖아</td>\n",
       "      <td>아무래도 가장 큰 건 코로나 아닐까?</td>\n",
       "      <td>요즘 사회적 이슈들은 뭐가 있을까?</td>\n",
       "      <td>다 벌 받을 거야 나쁜 사람들 ㅠ</td>\n",
       "      <td>**이 알레르기 있어서 만지지도 못하고 안타깝다 정말 귀여운데</td>\n",
       "      <td>고양이도 소중한 생명인데 길거리에 버려진 고양이들 보면 너무 안타까워</td>\n",
       "      <td>우리 원룸 주변에 보면 아직도 길고양이들 돌아다니고 하더라고 ㅠㅠ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>그치 우리한테는 직접적으로까진 아니어도 분명 영향을 줄 거야 대통령이라는 사람은</td>\n",
       "      <td>내가 생각했을 때 대통령이 제일 중요한 인물이기 때문에 좋은 사람이 되기를 바래야지 ㅠㅠ</td>\n",
       "      <td>다음 대통령은 과연 누가 될까? 궁금하다</td>\n",
       "      <td>다음 대통령은 꼭 코로나를 잡진 못하더라도 완만히 넘길 수 있는 대통령이 나왔으면 ...</td>\n",
       "      <td>코로나만 어떻게 해결된다면 사회적 이슈가 잦아질텐데 말이야...</td>\n",
       "      <td>거기다가 변이 바이러스까지 겹쳐서 걱정이다...</td>\n",
       "      <td>그게 난 정말 의문이야 ㅠㅠ</td>\n",
       "      <td>백신이 아직까지는 큰 효과를 보지는 못하는 거 같아...</td>\n",
       "      <td>그런데 백신을 그렇게 많은 사람들이 맞고 있는데 왜 더 늘어날까?</td>\n",
       "      <td>휴 추석이 끝나고 1주일 동안은 엄청 늘어날 거라고 하더니 그래도 생각보단 괜찮네 아직</td>\n",
       "      <td>코로나가 제일 심각한 문제긴 하지 우리나라 뿐만 아니라 전 세계적으로 문제가 있는 거라</td>\n",
       "      <td>며칠 전에 3200명이란 어마어마한 확진자가 발생했잖아</td>\n",
       "      <td>아무래도 가장 큰 건 코로나 아닐까?</td>\n",
       "      <td>요즘 사회적 이슈들은 뭐가 있을까?</td>\n",
       "      <td>다 벌 받을 거야 나쁜 사람들 ㅠ</td>\n",
       "      <td>**이 알레르기 있어서 만지지도 못하고 안타깝다 정말 귀여운데</td>\n",
       "      <td>고양이도 소중한 생명인데 길거리에 버려진 고양이들 보면 너무 안타까워</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217988</th>\n",
       "      <td>난 기대고 싶어요 키키</td>\n",
       "      <td>오빠도 좀차이가났어야되는데ㅡㅡ</td>\n",
       "      <td>키키 소리치고 키키 나도 뭐 생각안해봐서 키키</td>\n",
       "      <td>지는 오빠가 좋아요</td>\n",
       "      <td>난 내 보다 어린애가 내 이름 부르면 기분 나쁠 거 같아요 키키</td>\n",
       "      <td>헐 키키 니는 오빠가좋으나?</td>\n",
       "      <td>내 친구 신랑들은 한 열 살 많은 어르신 같음 키키</td>\n",
       "      <td>키키 결혼하면 다똑같음 키키</td>\n",
       "      <td>근데 뭔가 연하 하면은 되게 좀 사랑스럽고 키키 상큼하고 키키 이런 이미진데~</td>\n",
       "      <td>키키 그자? 나는 그냥 친구가 좋았는듯</td>\n",
       "      <td>근데 연하 느낌1도 안남 키키</td>\n",
       "      <td>내 친구 두명은 연하랑 결혼했거든요~</td>\n",
       "      <td>키키 미안 연하는 좀 안 맞는 듯 키키</td>\n",
       "      <td>나도 연하는 안 만나 봐서 궁금해서요 언니 키키</td>\n",
       "      <td>오빠도 1살 오빠 니는?</td>\n",
       "      <td>아니 난 동갑</td>\n",
       "      <td>언니 연하 남친 만나 봤어요?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217989</th>\n",
       "      <td>누가 나한테 기대는 거 말고 키키</td>\n",
       "      <td>난 기대고 싶어요 키키</td>\n",
       "      <td>오빠도 좀차이가났어야되는데ㅡㅡ</td>\n",
       "      <td>키키 소리치고 키키 나도 뭐 생각안해봐서 키키</td>\n",
       "      <td>지는 오빠가 좋아요</td>\n",
       "      <td>난 내 보다 어린애가 내 이름 부르면 기분 나쁠 거 같아요 키키</td>\n",
       "      <td>헐 키키 니는 오빠가좋으나?</td>\n",
       "      <td>내 친구 신랑들은 한 열 살 많은 어르신 같음 키키</td>\n",
       "      <td>키키 결혼하면 다똑같음 키키</td>\n",
       "      <td>근데 뭔가 연하 하면은 되게 좀 사랑스럽고 키키 상큼하고 키키 이런 이미진데~</td>\n",
       "      <td>키키 그자? 나는 그냥 친구가 좋았는듯</td>\n",
       "      <td>근데 연하 느낌1도 안남 키키</td>\n",
       "      <td>내 친구 두명은 연하랑 결혼했거든요~</td>\n",
       "      <td>키키 미안 연하는 좀 안 맞는 듯 키키</td>\n",
       "      <td>나도 연하는 안 만나 봐서 궁금해서요 언니 키키</td>\n",
       "      <td>오빠도 1살 오빠 니는?</td>\n",
       "      <td>아니 난 동갑</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217990</th>\n",
       "      <td>키키 그래 난 계속 독립적이다</td>\n",
       "      <td>누가 나한테 기대는 거 말고 키키</td>\n",
       "      <td>난 기대고 싶어요 키키</td>\n",
       "      <td>오빠도 좀차이가났어야되는데ㅡㅡ</td>\n",
       "      <td>키키 소리치고 키키 나도 뭐 생각안해봐서 키키</td>\n",
       "      <td>지는 오빠가 좋아요</td>\n",
       "      <td>난 내 보다 어린애가 내 이름 부르면 기분 나쁠 거 같아요 키키</td>\n",
       "      <td>헐 키키 니는 오빠가좋으나?</td>\n",
       "      <td>내 친구 신랑들은 한 열 살 많은 어르신 같음 키키</td>\n",
       "      <td>키키 결혼하면 다똑같음 키키</td>\n",
       "      <td>근데 뭔가 연하 하면은 되게 좀 사랑스럽고 키키 상큼하고 키키 이런 이미진데~</td>\n",
       "      <td>키키 그자? 나는 그냥 친구가 좋았는듯</td>\n",
       "      <td>근데 연하 느낌1도 안남 키키</td>\n",
       "      <td>내 친구 두명은 연하랑 결혼했거든요~</td>\n",
       "      <td>키키 미안 연하는 좀 안 맞는 듯 키키</td>\n",
       "      <td>나도 연하는 안 만나 봐서 궁금해서요 언니 키키</td>\n",
       "      <td>오빠도 1살 오빠 니는?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217991</th>\n",
       "      <td>그래~ 그리고 너 진짜 안 못생겼어</td>\n",
       "      <td>하긴 외모는 나의 일부분이니까</td>\n",
       "      <td>정말 좋은말이다 하하</td>\n",
       "      <td>외면의 모습 말고 내면의 모습을 가꿔봐</td>\n",
       "      <td>나 사춘기때부터 지금까지 있는걸? ㅠㅠ</td>\n",
       "      <td>잠깐이니까 너무 신경쓰지마</td>\n",
       "      <td>트러블이 평생 가는 건 아니잖아~</td>\n",
       "      <td>요즘 얼굴에 트러블도 많이 생겼거든</td>\n",
       "      <td>그런걸까? 고마워 ㅜㅜ</td>\n",
       "      <td>남의 기준에 널 맞추지마</td>\n",
       "      <td>그럴필요 없어~</td>\n",
       "      <td>근데 요즘 거울 보면 자신감이 없어ㅜㅜ</td>\n",
       "      <td>내가 봤을때 너는 아주 예뻐</td>\n",
       "      <td>외모는 다 각자만의 기준이 있는거야</td>\n",
       "      <td>아니 어제 만난 친구가 나보고 얼굴이 변했대 ㅜㅜ</td>\n",
       "      <td>무슨 소리야 아니야</td>\n",
       "      <td>나 못생겼어?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217992</th>\n",
       "      <td>햇볕이 잘 드는 곳에 키우면 튼튼하게 자라고 꽃도 오래 감 상할 수 있어.</td>\n",
       "      <td>다육식물은 난과식물, 파인애플과 식물과 마찬가지로 밤에 이산화탄소를 흡수하므로 꽃이...</td>\n",
       "      <td>일년내내 꽃을 피우는 성질이 강하나 빛이 부족하거나 저온과 건조에서는 낙엽이 지고 ...</td>\n",
       "      <td>추위에 강해 3~5℃에서 월동이 가능하나, 겨울철에도 개화를 계속시키고자 할 때에는...</td>\n",
       "      <td>분갈이는 봄에 필요한 경우에 실시해</td>\n",
       "      <td>용토는 모래와 부엽(피트모스) 등을 배합하여 배수성과 보 수성이 좋게해</td>\n",
       "      <td>저온과 건조 상태에서는 잎이 떨어지는 현상이 있어 수분을 연중 유지해야 해</td>\n",
       "      <td>가지치기를 하지 않으면 웃자라 주변 식물의 생장에 영향을 줘</td>\n",
       "      <td>건조에 강해.</td>\n",
       "      <td>겨울은 다른 계절에 비해 적게 물을 줘</td>\n",
       "      <td>화분흙이 마르면 물을 충분히 줘</td>\n",
       "      <td>꺾꽂이를 할 때 절단면에서 흐르는 흰색 액체를 깨끗이 씻어 낸 후 흙에 꽂으면 됨.</td>\n",
       "      <td>파종과 꺾꽂이로 번식하는데 보통 봄에 하는 것이 좋아</td>\n",
       "      <td>줄기에 홈이 있고 날카로운 가시로 덮여있어 가시에 주의해야 해</td>\n",
       "      <td>빨간색, 연노란색, 흰색, 주황색 등 꽃 색상이 다양해 취향에 따라 선택할 수 있어</td>\n",
       "      <td>꽃이 솟아 오른 모양이 기린을 닮았다고 하여 꽃기린이라는 이름이 붙었어</td>\n",
       "      <td>스플렌덴스 꽃기린(꽃기린)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>217993 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 response  \\\n",
       "0                     코로나만 어떻게 해결된다면 사회적 이슈가 잦아질텐데 말이야...   \n",
       "1       다음 대통령은 꼭 코로나를 잡진 못하더라도 완만히 넘길 수 있는 대통령이 나왔으면 ...   \n",
       "2                                  다음 대통령은 과연 누가 될까? 궁금하다   \n",
       "3       내가 생각했을 때 대통령이 제일 중요한 인물이기 때문에 좋은 사람이 되기를 바래야지 ㅠㅠ   \n",
       "4            그치 우리한테는 직접적으로까진 아니어도 분명 영향을 줄 거야 대통령이라는 사람은   \n",
       "...                                                   ...   \n",
       "217988                                       난 기대고 싶어요 키키   \n",
       "217989                                 누가 나한테 기대는 거 말고 키키   \n",
       "217990                                   키키 그래 난 계속 독립적이다   \n",
       "217991                                그래~ 그리고 너 진짜 안 못생겼어   \n",
       "217992          햇볕이 잘 드는 곳에 키우면 튼튼하게 자라고 꽃도 오래 감 상할 수 있어.   \n",
       "\n",
       "                                                  context  \\\n",
       "0                              거기다가 변이 바이러스까지 겹쳐서 걱정이다...   \n",
       "1                     코로나만 어떻게 해결된다면 사회적 이슈가 잦아질텐데 말이야...   \n",
       "2       다음 대통령은 꼭 코로나를 잡진 못하더라도 완만히 넘길 수 있는 대통령이 나왔으면 ...   \n",
       "3                                  다음 대통령은 과연 누가 될까? 궁금하다   \n",
       "4       내가 생각했을 때 대통령이 제일 중요한 인물이기 때문에 좋은 사람이 되기를 바래야지 ㅠㅠ   \n",
       "...                                                   ...   \n",
       "217988                                   오빠도 좀차이가났어야되는데ㅡㅡ   \n",
       "217989                                       난 기대고 싶어요 키키   \n",
       "217990                                 누가 나한테 기대는 거 말고 키키   \n",
       "217991                                   하긴 외모는 나의 일부분이니까   \n",
       "217992  다육식물은 난과식물, 파인애플과 식물과 마찬가지로 밤에 이산화탄소를 흡수하므로 꽃이...   \n",
       "\n",
       "                                                context/0  \\\n",
       "0                                         그게 난 정말 의문이야 ㅠㅠ   \n",
       "1                              거기다가 변이 바이러스까지 겹쳐서 걱정이다...   \n",
       "2                     코로나만 어떻게 해결된다면 사회적 이슈가 잦아질텐데 말이야...   \n",
       "3       다음 대통령은 꼭 코로나를 잡진 못하더라도 완만히 넘길 수 있는 대통령이 나왔으면 ...   \n",
       "4                                  다음 대통령은 과연 누가 될까? 궁금하다   \n",
       "...                                                   ...   \n",
       "217988                          키키 소리치고 키키 나도 뭐 생각안해봐서 키키   \n",
       "217989                                   오빠도 좀차이가났어야되는데ㅡㅡ   \n",
       "217990                                       난 기대고 싶어요 키키   \n",
       "217991                                        정말 좋은말이다 하하   \n",
       "217992  일년내내 꽃을 피우는 성질이 강하나 빛이 부족하거나 저온과 건조에서는 낙엽이 지고 ...   \n",
       "\n",
       "                                                context/1  \\\n",
       "0                         백신이 아직까지는 큰 효과를 보지는 못하는 거 같아...   \n",
       "1                                         그게 난 정말 의문이야 ㅠㅠ   \n",
       "2                              거기다가 변이 바이러스까지 겹쳐서 걱정이다...   \n",
       "3                     코로나만 어떻게 해결된다면 사회적 이슈가 잦아질텐데 말이야...   \n",
       "4       다음 대통령은 꼭 코로나를 잡진 못하더라도 완만히 넘길 수 있는 대통령이 나왔으면 ...   \n",
       "...                                                   ...   \n",
       "217988                                         지는 오빠가 좋아요   \n",
       "217989                          키키 소리치고 키키 나도 뭐 생각안해봐서 키키   \n",
       "217990                                   오빠도 좀차이가났어야되는데ㅡㅡ   \n",
       "217991                              외면의 모습 말고 내면의 모습을 가꿔봐   \n",
       "217992  추위에 강해 3~5℃에서 월동이 가능하나, 겨울철에도 개화를 계속시키고자 할 때에는...   \n",
       "\n",
       "                                   context/2  \\\n",
       "0       그런데 백신을 그렇게 많은 사람들이 맞고 있는데 왜 더 늘어날까?   \n",
       "1            백신이 아직까지는 큰 효과를 보지는 못하는 거 같아...   \n",
       "2                            그게 난 정말 의문이야 ㅠㅠ   \n",
       "3                 거기다가 변이 바이러스까지 겹쳐서 걱정이다...   \n",
       "4        코로나만 어떻게 해결된다면 사회적 이슈가 잦아질텐데 말이야...   \n",
       "...                                      ...   \n",
       "217988   난 내 보다 어린애가 내 이름 부르면 기분 나쁠 거 같아요 키키   \n",
       "217989                            지는 오빠가 좋아요   \n",
       "217990             키키 소리치고 키키 나도 뭐 생각안해봐서 키키   \n",
       "217991                 나 사춘기때부터 지금까지 있는걸? ㅠㅠ   \n",
       "217992                   분갈이는 봄에 필요한 경우에 실시해   \n",
       "\n",
       "                                               context/3  \\\n",
       "0       휴 추석이 끝나고 1주일 동안은 엄청 늘어날 거라고 하더니 그래도 생각보단 괜찮네 아직   \n",
       "1                   그런데 백신을 그렇게 많은 사람들이 맞고 있는데 왜 더 늘어날까?   \n",
       "2                        백신이 아직까지는 큰 효과를 보지는 못하는 거 같아...   \n",
       "3                                        그게 난 정말 의문이야 ㅠㅠ   \n",
       "4                             거기다가 변이 바이러스까지 겹쳐서 걱정이다...   \n",
       "...                                                  ...   \n",
       "217988                                   헐 키키 니는 오빠가좋으나?   \n",
       "217989               난 내 보다 어린애가 내 이름 부르면 기분 나쁠 거 같아요 키키   \n",
       "217990                                        지는 오빠가 좋아요   \n",
       "217991                                    잠깐이니까 너무 신경쓰지마   \n",
       "217992           용토는 모래와 부엽(피트모스) 등을 배합하여 배수성과 보 수성이 좋게해   \n",
       "\n",
       "                                               context/4  \\\n",
       "0       코로나가 제일 심각한 문제긴 하지 우리나라 뿐만 아니라 전 세계적으로 문제가 있는 거라   \n",
       "1       휴 추석이 끝나고 1주일 동안은 엄청 늘어날 거라고 하더니 그래도 생각보단 괜찮네 아직   \n",
       "2                   그런데 백신을 그렇게 많은 사람들이 맞고 있는데 왜 더 늘어날까?   \n",
       "3                        백신이 아직까지는 큰 효과를 보지는 못하는 거 같아...   \n",
       "4                                        그게 난 정말 의문이야 ㅠㅠ   \n",
       "...                                                  ...   \n",
       "217988                      내 친구 신랑들은 한 열 살 많은 어르신 같음 키키   \n",
       "217989                                   헐 키키 니는 오빠가좋으나?   \n",
       "217990               난 내 보다 어린애가 내 이름 부르면 기분 나쁠 거 같아요 키키   \n",
       "217991                                트러블이 평생 가는 건 아니잖아~   \n",
       "217992         저온과 건조 상태에서는 잎이 떨어지는 현상이 있어 수분을 연중 유지해야 해   \n",
       "\n",
       "                                               context/5  \\\n",
       "0                         며칠 전에 3200명이란 어마어마한 확진자가 발생했잖아   \n",
       "1       코로나가 제일 심각한 문제긴 하지 우리나라 뿐만 아니라 전 세계적으로 문제가 있는 거라   \n",
       "2       휴 추석이 끝나고 1주일 동안은 엄청 늘어날 거라고 하더니 그래도 생각보단 괜찮네 아직   \n",
       "3                   그런데 백신을 그렇게 많은 사람들이 맞고 있는데 왜 더 늘어날까?   \n",
       "4                        백신이 아직까지는 큰 효과를 보지는 못하는 거 같아...   \n",
       "...                                                  ...   \n",
       "217988                                   키키 결혼하면 다똑같음 키키   \n",
       "217989                      내 친구 신랑들은 한 열 살 많은 어르신 같음 키키   \n",
       "217990                                   헐 키키 니는 오빠가좋으나?   \n",
       "217991                               요즘 얼굴에 트러블도 많이 생겼거든   \n",
       "217992                 가지치기를 하지 않으면 웃자라 주변 식물의 생장에 영향을 줘   \n",
       "\n",
       "                                               context/6  \\\n",
       "0                                   아무래도 가장 큰 건 코로나 아닐까?   \n",
       "1                         며칠 전에 3200명이란 어마어마한 확진자가 발생했잖아   \n",
       "2       코로나가 제일 심각한 문제긴 하지 우리나라 뿐만 아니라 전 세계적으로 문제가 있는 거라   \n",
       "3       휴 추석이 끝나고 1주일 동안은 엄청 늘어날 거라고 하더니 그래도 생각보단 괜찮네 아직   \n",
       "4                   그런데 백신을 그렇게 많은 사람들이 맞고 있는데 왜 더 늘어날까?   \n",
       "...                                                  ...   \n",
       "217988       근데 뭔가 연하 하면은 되게 좀 사랑스럽고 키키 상큼하고 키키 이런 이미진데~   \n",
       "217989                                   키키 결혼하면 다똑같음 키키   \n",
       "217990                      내 친구 신랑들은 한 열 살 많은 어르신 같음 키키   \n",
       "217991                                      그런걸까? 고마워 ㅜㅜ   \n",
       "217992                                           건조에 강해.   \n",
       "\n",
       "                                               context/7  \\\n",
       "0                                    요즘 사회적 이슈들은 뭐가 있을까?   \n",
       "1                                   아무래도 가장 큰 건 코로나 아닐까?   \n",
       "2                         며칠 전에 3200명이란 어마어마한 확진자가 발생했잖아   \n",
       "3       코로나가 제일 심각한 문제긴 하지 우리나라 뿐만 아니라 전 세계적으로 문제가 있는 거라   \n",
       "4       휴 추석이 끝나고 1주일 동안은 엄청 늘어날 거라고 하더니 그래도 생각보단 괜찮네 아직   \n",
       "...                                                  ...   \n",
       "217988                             키키 그자? 나는 그냥 친구가 좋았는듯   \n",
       "217989       근데 뭔가 연하 하면은 되게 좀 사랑스럽고 키키 상큼하고 키키 이런 이미진데~   \n",
       "217990                                   키키 결혼하면 다똑같음 키키   \n",
       "217991                                     남의 기준에 널 맞추지마   \n",
       "217992                             겨울은 다른 계절에 비해 적게 물을 줘   \n",
       "\n",
       "                                               context/8  \\\n",
       "0                                     다 벌 받을 거야 나쁜 사람들 ㅠ   \n",
       "1                                    요즘 사회적 이슈들은 뭐가 있을까?   \n",
       "2                                   아무래도 가장 큰 건 코로나 아닐까?   \n",
       "3                         며칠 전에 3200명이란 어마어마한 확진자가 발생했잖아   \n",
       "4       코로나가 제일 심각한 문제긴 하지 우리나라 뿐만 아니라 전 세계적으로 문제가 있는 거라   \n",
       "...                                                  ...   \n",
       "217988                                  근데 연하 느낌1도 안남 키키   \n",
       "217989                             키키 그자? 나는 그냥 친구가 좋았는듯   \n",
       "217990       근데 뭔가 연하 하면은 되게 좀 사랑스럽고 키키 상큼하고 키키 이런 이미진데~   \n",
       "217991                                          그럴필요 없어~   \n",
       "217992                                 화분흙이 마르면 물을 충분히 줘   \n",
       "\n",
       "                                             context/9  \\\n",
       "0                   **이 알레르기 있어서 만지지도 못하고 안타깝다 정말 귀여운데   \n",
       "1                                   다 벌 받을 거야 나쁜 사람들 ㅠ   \n",
       "2                                  요즘 사회적 이슈들은 뭐가 있을까?   \n",
       "3                                 아무래도 가장 큰 건 코로나 아닐까?   \n",
       "4                       며칠 전에 3200명이란 어마어마한 확진자가 발생했잖아   \n",
       "...                                                ...   \n",
       "217988                            내 친구 두명은 연하랑 결혼했거든요~   \n",
       "217989                                근데 연하 느낌1도 안남 키키   \n",
       "217990                           키키 그자? 나는 그냥 친구가 좋았는듯   \n",
       "217991                           근데 요즘 거울 보면 자신감이 없어ㅜㅜ   \n",
       "217992  꺾꽂이를 할 때 절단면에서 흐르는 흰색 액체를 깨끗이 씻어 낸 후 흙에 꽂으면 됨.   \n",
       "\n",
       "                                    context/10  \\\n",
       "0       고양이도 소중한 생명인데 길거리에 버려진 고양이들 보면 너무 안타까워   \n",
       "1           **이 알레르기 있어서 만지지도 못하고 안타깝다 정말 귀여운데   \n",
       "2                           다 벌 받을 거야 나쁜 사람들 ㅠ   \n",
       "3                          요즘 사회적 이슈들은 뭐가 있을까?   \n",
       "4                         아무래도 가장 큰 건 코로나 아닐까?   \n",
       "...                                        ...   \n",
       "217988                   키키 미안 연하는 좀 안 맞는 듯 키키   \n",
       "217989                    내 친구 두명은 연하랑 결혼했거든요~   \n",
       "217990                        근데 연하 느낌1도 안남 키키   \n",
       "217991                         내가 봤을때 너는 아주 예뻐   \n",
       "217992           파종과 꺾꽂이로 번식하는데 보통 봄에 하는 것이 좋아   \n",
       "\n",
       "                                    context/11  \\\n",
       "0         우리 원룸 주변에 보면 아직도 길고양이들 돌아다니고 하더라고 ㅠㅠ   \n",
       "1       고양이도 소중한 생명인데 길거리에 버려진 고양이들 보면 너무 안타까워   \n",
       "2           **이 알레르기 있어서 만지지도 못하고 안타깝다 정말 귀여운데   \n",
       "3                           다 벌 받을 거야 나쁜 사람들 ㅠ   \n",
       "4                          요즘 사회적 이슈들은 뭐가 있을까?   \n",
       "...                                        ...   \n",
       "217988              나도 연하는 안 만나 봐서 궁금해서요 언니 키키   \n",
       "217989                   키키 미안 연하는 좀 안 맞는 듯 키키   \n",
       "217990                    내 친구 두명은 연하랑 결혼했거든요~   \n",
       "217991                     외모는 다 각자만의 기준이 있는거야   \n",
       "217992      줄기에 홈이 있고 날카로운 가시로 덮여있어 가시에 주의해야 해   \n",
       "\n",
       "                                            context/12  \\\n",
       "0              그치 동물들도 요즘 사회적 이슈고 요즘 또 이슈화 있는 사건이 많더라고   \n",
       "1                 우리 원룸 주변에 보면 아직도 길고양이들 돌아다니고 하더라고 ㅠㅠ   \n",
       "2               고양이도 소중한 생명인데 길거리에 버려진 고양이들 보면 너무 안타까워   \n",
       "3                   **이 알레르기 있어서 만지지도 못하고 안타깝다 정말 귀여운데   \n",
       "4                                   다 벌 받을 거야 나쁜 사람들 ㅠ   \n",
       "...                                                ...   \n",
       "217988                                   오빠도 1살 오빠 니는?   \n",
       "217989                      나도 연하는 안 만나 봐서 궁금해서요 언니 키키   \n",
       "217990                           키키 미안 연하는 좀 안 맞는 듯 키키   \n",
       "217991                     아니 어제 만난 친구가 나보고 얼굴이 변했대 ㅜㅜ   \n",
       "217992  빨간색, 연노란색, 흰색, 주황색 등 꽃 색상이 다양해 취향에 따라 선택할 수 있어   \n",
       "\n",
       "                                     context/13  \\\n",
       "0                        동물들을 유기 하는 사람이 아직도 있어?   \n",
       "1       그치 동물들도 요즘 사회적 이슈고 요즘 또 이슈화 있는 사건이 많더라고   \n",
       "2          우리 원룸 주변에 보면 아직도 길고양이들 돌아다니고 하더라고 ㅠㅠ   \n",
       "3        고양이도 소중한 생명인데 길거리에 버려진 고양이들 보면 너무 안타까워   \n",
       "4            **이 알레르기 있어서 만지지도 못하고 안타깝다 정말 귀여운데   \n",
       "...                                         ...   \n",
       "217988                                  아니 난 동갑   \n",
       "217989                            오빠도 1살 오빠 니는?   \n",
       "217990               나도 연하는 안 만나 봐서 궁금해서요 언니 키키   \n",
       "217991                               무슨 소리야 아니야   \n",
       "217992  꽃이 솟아 오른 모양이 기린을 닮았다고 하여 꽃기린이라는 이름이 붙었어   \n",
       "\n",
       "                                     context/14  \n",
       "0                    요즘 동물들을 유기 하는 애들도 참 문제야 ㅠㅠ  \n",
       "1                        동물들을 유기 하는 사람이 아직도 있어?  \n",
       "2       그치 동물들도 요즘 사회적 이슈고 요즘 또 이슈화 있는 사건이 많더라고  \n",
       "3          우리 원룸 주변에 보면 아직도 길고양이들 돌아다니고 하더라고 ㅠㅠ  \n",
       "4        고양이도 소중한 생명인데 길거리에 버려진 고양이들 보면 너무 안타까워  \n",
       "...                                         ...  \n",
       "217988                         언니 연하 남친 만나 봤어요?  \n",
       "217989                                  아니 난 동갑  \n",
       "217990                            오빠도 1살 오빠 니는?  \n",
       "217991                                  나 못생겼어?  \n",
       "217992                           스플렌덴스 꽃기린(꽃기린)  \n",
       "\n",
       "[217993 rows x 17 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['response', 'context'] \n",
    "columns = columns + ['context/' + str(i) for i in range(WINDOW - 2)]\n",
    "\n",
    "df = pd.DataFrame.from_records(train_data, columns=columns)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 739
    },
    "executionInfo": {
     "elapsed": 852,
     "status": "ok",
     "timestamp": 1666354251175,
     "user": {
      "displayName": "차준혁",
      "userId": "06162925735462569720"
     },
     "user_tz": -540
    },
    "id": "Ac4Z0Z57jY2I",
    "outputId": "4eba24f1-7d8d-489c-ee73-802d8c0323bc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>response</th>\n",
       "      <th>context</th>\n",
       "      <th>context/0</th>\n",
       "      <th>context/1</th>\n",
       "      <th>context/2</th>\n",
       "      <th>context/3</th>\n",
       "      <th>context/4</th>\n",
       "      <th>context/5</th>\n",
       "      <th>context/6</th>\n",
       "      <th>context/7</th>\n",
       "      <th>context/8</th>\n",
       "      <th>context/9</th>\n",
       "      <th>context/10</th>\n",
       "      <th>context/11</th>\n",
       "      <th>context/12</th>\n",
       "      <th>context/13</th>\n",
       "      <th>context/14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>72564</th>\n",
       "      <td>몰라 키키</td>\n",
       "      <td>진짜? 키키 왜 만들어 놓은 거야 키키</td>\n",
       "      <td>아? 키키 집에 설치하느라 힘들었나 보네 키키</td>\n",
       "      <td>근데 설치해놓고 지쳤나 안 쓰더라 키키</td>\n",
       "      <td>그러게ㅜㅜ 맨날 친구 집에 놀러 가는 거 아니야? 키키</td>\n",
       "      <td>친구 부럽다 ㅠㅠ</td>\n",
       "      <td>헐... 완전 내 워너비 ㅠㅠ</td>\n",
       "      <td>내 친구는 주택에 사는데 옥상에다 아예 캠핑장을 만들어놨어 키키</td>\n",
       "      <td>거의 꿈의 이야기다 ㅜㅜ</td>\n",
       "      <td>그럼 진짜 좋지 키키</td>\n",
       "      <td>집에 바베큐장 딱 만들어 놓고 주말마다 바베큐 파티하고 ㅠㅠ</td>\n",
       "      <td>그러게 갑자기 현타가 오네 키키</td>\n",
       "      <td>뭐야 둘 다 가능성이 희박해 ㅜㅜ</td>\n",
       "      <td>그치... 주택 살거나 건물주라 옥상에 바베큐장을 만들거나...키키</td>\n",
       "      <td>맞아 키키 주택 사는 거 아니면 힘들지 않나?</td>\n",
       "      <td>집에 바베큐장 있으면 대박이지 키키</td>\n",
       "      <td>집에 바베큐장 있었으면 좋겠다 ㅠㅠ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132048</th>\n",
       "      <td>다들 무조건 아이스구나 키키</td>\n",
       "      <td>따뜻한 커피는 왜 맛이 없니...?</td>\n",
       "      <td>물도 같이 꼭 먹어야 해</td>\n",
       "      <td>힘이 안나 커피 안 마시면</td>\n",
       "      <td>물을 많이 마셔야 한데 진짜...!</td>\n",
       "      <td>나도 무조건 아이스 먹어</td>\n",
       "      <td>물도 많이 마셔줘야 한다구</td>\n",
       "      <td>얼죽아지 키키 물 마셔야 해</td>\n",
       "      <td>아니면 기분이 안 좋아 키키</td>\n",
       "      <td>물도 많이 마셔줘야 해 ㅠㅠ</td>\n",
       "      <td>나도 당근 아이스지 하하</td>\n",
       "      <td>하루 한잔 커피 필수지 ㅠㅠ</td>\n",
       "      <td>얼죽아니 다들? 맞아 한잔 필수</td>\n",
       "      <td>하루 한잔 필수야</td>\n",
       "      <td>나는 물 먹고 있어 지금</td>\n",
       "      <td>얼죽아야 겨울에도 아이스 하하</td>\n",
       "      <td>난 커피 마시는 중... 하하</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199219</th>\n",
       "      <td>사직 구장 새로 짓는다고 하더라</td>\n",
       "      <td>역시 기업이 운영해야 된다 스포츠는</td>\n",
       "      <td>나는 모르는 소리야 키키</td>\n",
       "      <td>스타벅스 생기고 개쩜...</td>\n",
       "      <td>랜더스 세련되고 현대적이야</td>\n",
       "      <td>코로나라서 잘 안 팔리나?</td>\n",
       "      <td>키키 랜더스 요즘 난리잖아 ㅠ</td>\n",
       "      <td>직관 자주 온대</td>\n",
       "      <td>용진이형 하하 보고싶당</td>\n",
       "      <td>지금 할인이면 바로 고고해야지</td>\n",
       "      <td>코로나 어쩌고 해서 50%!</td>\n",
       "      <td>용진이형 랜더스 응원하고 싶음 야구</td>\n",
       "      <td>나도 야구장 안 간지 오래됨 ㅜㅜ</td>\n",
       "      <td>야구장 지금 할인한데</td>\n",
       "      <td>지금이라도 농구 하면 키 크려나</td>\n",
       "      <td>윽 요즘은 비시즌인가?</td>\n",
       "      <td>야구장 가고 싶다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140467</th>\n",
       "      <td>네 지금 생각해보면 그랬던 것 같아요 키키</td>\n",
       "      <td>***님 스트레스 해소용? 키키</td>\n",
       "      <td>한마디로 감정 쓰레기통이었다는</td>\n",
       "      <td>키키</td>\n",
       "      <td>저도 참 못된게 맘 힘들고 그럴때 전화해서 꼬장부렸어요</td>\n",
       "      <td>제가 서울 살때 헤어졌는데</td>\n",
       "      <td>정 다 떨어지고 헤어진거라</td>\n",
       "      <td>전 헤어지고는 쿨하게 떠나는데...</td>\n",
       "      <td>남자도 참...</td>\n",
       "      <td>저 찾으면서 키키</td>\n",
       "      <td>키키</td>\n",
       "      <td>대학 선배들 동기들 다 친하니까 모임같은것도 많았는데 그때마다 울었대요</td>\n",
       "      <td>욕하고 그랬어요? 키키</td>\n",
       "      <td>엄청 했어요</td>\n",
       "      <td>술먹고 꼬장 키키 여자가 하는건 처음봤어요 키키</td>\n",
       "      <td>술먹고 전화해서 꼬장부리구요 네네</td>\n",
       "      <td>다시 사귀어줄거처럼? 키키</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196581</th>\n",
       "      <td>그림은 귀엽고 스토리도 괜찮던데... 다음에 시간 좀 많을 때 한번 다시 도전해봐야겠어.</td>\n",
       "      <td>맞아...시작한지 얼마안됐는데 접어야할까봐.</td>\n",
       "      <td>스토리가 좀 재미있어서 하다가 너무 어렵고 화가나서 못하겠어.</td>\n",
       "      <td>나는 원래 못하는 편이긴 한데...</td>\n",
       "      <td>내가 진짜 게임 못하는 편이 아닌데, 블소는 나랑 안맞는지 죽고 또 죽고 또또 죽더라.</td>\n",
       "      <td>ㅋ엄청 욕먹었잖아</td>\n",
       "      <td>나는 내가 앞장서서 몬스터랑 싸우고 그래야하는데 그런건지도 모르고 맨 뒤에서 혼자 ...</td>\n",
       "      <td>그거 너무 과하게 어려워 ㅠㅠ</td>\n",
       "      <td>나는 그거 파티사냥 해볼라다가 내가 계속 죽어서 못하겠어서 접었어... ㅠㅠ</td>\n",
       "      <td>그래서 잘 못해 키키</td>\n",
       "      <td>응 어려워 ㅋ</td>\n",
       "      <td>인던에서 무슨 페이즈 맞춰서 공격하는것도 엄청 어렵던데</td>\n",
       "      <td>막 하늘 나는법도 어렵고...</td>\n",
       "      <td>야 그거 잠깐 해봤는데 어렵던데;</td>\n",
       "      <td>오 그거 재밌나?</td>\n",
       "      <td>나 요새 친구랑 블레이드 앤 소울해 ㅋ</td>\n",
       "      <td>새로나온것도 없고 모르겠따</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 response  \\\n",
       "72564                                               몰라 키키   \n",
       "132048                                    다들 무조건 아이스구나 키키   \n",
       "199219                                  사직 구장 새로 짓는다고 하더라   \n",
       "140467                            네 지금 생각해보면 그랬던 것 같아요 키키   \n",
       "196581  그림은 귀엽고 스토리도 괜찮던데... 다음에 시간 좀 많을 때 한번 다시 도전해봐야겠어.   \n",
       "\n",
       "                         context                           context/0  \\\n",
       "72564      진짜? 키키 왜 만들어 놓은 거야 키키           아? 키키 집에 설치하느라 힘들었나 보네 키키   \n",
       "132048       따뜻한 커피는 왜 맛이 없니...?                       물도 같이 꼭 먹어야 해   \n",
       "199219       역시 기업이 운영해야 된다 스포츠는                       나는 모르는 소리야 키키   \n",
       "140467         ***님 스트레스 해소용? 키키                    한마디로 감정 쓰레기통이었다는   \n",
       "196581  맞아...시작한지 얼마안됐는데 접어야할까봐.  스토리가 좀 재미있어서 하다가 너무 어렵고 화가나서 못하겠어.   \n",
       "\n",
       "                    context/1  \\\n",
       "72564   근데 설치해놓고 지쳤나 안 쓰더라 키키   \n",
       "132048         힘이 안나 커피 안 마시면   \n",
       "199219         스타벅스 생기고 개쩜...   \n",
       "140467                     키키   \n",
       "196581    나는 원래 못하는 편이긴 한데...   \n",
       "\n",
       "                                               context/2       context/3  \\\n",
       "72564                     그러게ㅜㅜ 맨날 친구 집에 놀러 가는 거 아니야? 키키       친구 부럽다 ㅠㅠ   \n",
       "132048                               물을 많이 마셔야 한데 진짜...!   나도 무조건 아이스 먹어   \n",
       "199219                                    랜더스 세련되고 현대적이야  코로나라서 잘 안 팔리나?   \n",
       "140467                    저도 참 못된게 맘 힘들고 그럴때 전화해서 꼬장부렸어요  제가 서울 살때 헤어졌는데   \n",
       "196581  내가 진짜 게임 못하는 편이 아닌데, 블소는 나랑 안맞는지 죽고 또 죽고 또또 죽더라.       ㅋ엄청 욕먹었잖아   \n",
       "\n",
       "                                                context/4  \\\n",
       "72564                                    헐... 완전 내 워너비 ㅠㅠ   \n",
       "132048                                     물도 많이 마셔줘야 한다구   \n",
       "199219                                   키키 랜더스 요즘 난리잖아 ㅠ   \n",
       "140467                                     정 다 떨어지고 헤어진거라   \n",
       "196581  나는 내가 앞장서서 몬스터랑 싸우고 그래야하는데 그런건지도 모르고 맨 뒤에서 혼자 ...   \n",
       "\n",
       "                                  context/5  \\\n",
       "72564   내 친구는 주택에 사는데 옥상에다 아예 캠핑장을 만들어놨어 키키   \n",
       "132048                      얼죽아지 키키 물 마셔야 해   \n",
       "199219                             직관 자주 온대   \n",
       "140467                  전 헤어지고는 쿨하게 떠나는데...   \n",
       "196581                     그거 너무 과하게 어려워 ㅠㅠ   \n",
       "\n",
       "                                         context/6         context/7  \\\n",
       "72564                                거의 꿈의 이야기다 ㅜㅜ       그럼 진짜 좋지 키키   \n",
       "132048                             아니면 기분이 안 좋아 키키   물도 많이 마셔줘야 해 ㅠㅠ   \n",
       "199219                                용진이형 하하 보고싶당  지금 할인이면 바로 고고해야지   \n",
       "140467                                    남자도 참...         저 찾으면서 키키   \n",
       "196581  나는 그거 파티사냥 해볼라다가 내가 계속 죽어서 못하겠어서 접었어... ㅠㅠ       그래서 잘 못해 키키   \n",
       "\n",
       "                                context/8  \\\n",
       "72564   집에 바베큐장 딱 만들어 놓고 주말마다 바베큐 파티하고 ㅠㅠ   \n",
       "132048                      나도 당근 아이스지 하하   \n",
       "199219                    코로나 어쩌고 해서 50%!   \n",
       "140467                                 키키   \n",
       "196581                            응 어려워 ㅋ   \n",
       "\n",
       "                                      context/9          context/10  \\\n",
       "72564                         그러게 갑자기 현타가 오네 키키  뭐야 둘 다 가능성이 희박해 ㅜㅜ   \n",
       "132048                          하루 한잔 커피 필수지 ㅠㅠ   얼죽아니 다들? 맞아 한잔 필수   \n",
       "199219                      용진이형 랜더스 응원하고 싶음 야구  나도 야구장 안 간지 오래됨 ㅜㅜ   \n",
       "140467  대학 선배들 동기들 다 친하니까 모임같은것도 많았는데 그때마다 울었대요        욕하고 그랬어요? 키키   \n",
       "196581           인던에서 무슨 페이즈 맞춰서 공격하는것도 엄청 어렵던데    막 하늘 나는법도 어렵고...   \n",
       "\n",
       "                                   context/11                  context/12  \\\n",
       "72564   그치... 주택 살거나 건물주라 옥상에 바베큐장을 만들거나...키키   맞아 키키 주택 사는 거 아니면 힘들지 않나?   \n",
       "132048                              하루 한잔 필수야               나는 물 먹고 있어 지금   \n",
       "199219                            야구장 지금 할인한데           지금이라도 농구 하면 키 크려나   \n",
       "140467                                 엄청 했어요  술먹고 꼬장 키키 여자가 하는건 처음봤어요 키키   \n",
       "196581                     야 그거 잠깐 해봤는데 어렵던데;                   오 그거 재밌나?   \n",
       "\n",
       "                   context/13           context/14  \n",
       "72564     집에 바베큐장 있으면 대박이지 키키  집에 바베큐장 있었으면 좋겠다 ㅠㅠ  \n",
       "132048       얼죽아야 겨울에도 아이스 하하     난 커피 마시는 중... 하하  \n",
       "199219           윽 요즘은 비시즌인가?            야구장 가고 싶다  \n",
       "140467     술먹고 전화해서 꼬장부리구요 네네       다시 사귀어줄거처럼? 키키  \n",
       "196581  나 요새 친구랑 블레이드 앤 소울해 ㅋ       새로나온것도 없고 모르겠따  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_df, val_df = train_test_split(df, test_size=0.1)\n",
    "trn_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "mMBuSkaLkJOD"
   },
   "outputs": [],
   "source": [
    "# Cacheing and storing of data/checkpoints\n",
    "\n",
    "def load_and_cache_examples(args, tokenizer, df_trn, df_val, evaluate=False):\n",
    "    return ConversationDataset(tokenizer, args, df_val if evaluate else df_trn)\n",
    "\n",
    "\n",
    "def set_seed(args):\n",
    "    random.seed(args.seed)\n",
    "    np.random.seed(args.seed)\n",
    "    torch.manual_seed(args.seed)\n",
    "    if args.n_gpu > 0:\n",
    "        torch.cuda.manual_seed_all(args.seed)\n",
    "\n",
    "\n",
    "def _sorted_checkpoints(args, checkpoint_prefix=\"checkpoint\", use_mtime=False) -> List[str]:\n",
    "    ordering_and_checkpoint_path = []\n",
    "\n",
    "    glob_checkpoints = glob.glob(os.path.join(args.output_dir, \"{}-*\".format(checkpoint_prefix)))\n",
    "\n",
    "    for path in glob_checkpoints:\n",
    "        if use_mtime:\n",
    "            ordering_and_checkpoint_path.append((os.path.getmtime(path), path))\n",
    "        else:\n",
    "            regex_match = re.match(\".*{}-([0-9]+)\".format(checkpoint_prefix), path)\n",
    "            if regex_match and regex_match.groups():\n",
    "                ordering_and_checkpoint_path.append((int(regex_match.groups()[0]), path))\n",
    "\n",
    "    checkpoints_sorted = sorted(ordering_and_checkpoint_path)\n",
    "    checkpoints_sorted = [checkpoint[1] for checkpoint in checkpoints_sorted]\n",
    "    return checkpoints_sorted\n",
    "\n",
    "\n",
    "def _rotate_checkpoints(args, checkpoint_prefix=\"checkpoint\", use_mtime=False) -> None:\n",
    "    if not args.save_total_limit:\n",
    "        return\n",
    "    if args.save_total_limit <= 0:\n",
    "        return\n",
    "\n",
    "    # Check if we should delete older checkpoint(s)\n",
    "    checkpoints_sorted = _sorted_checkpoints(args, checkpoint_prefix, use_mtime)\n",
    "    if len(checkpoints_sorted) <= args.save_total_limit:\n",
    "        return\n",
    "\n",
    "    number_of_checkpoints_to_delete = max(0, len(checkpoints_sorted) - args.save_total_limit)\n",
    "    checkpoints_to_be_deleted = checkpoints_sorted[:number_of_checkpoints_to_delete]\n",
    "    for checkpoint in checkpoints_to_be_deleted:\n",
    "        logger.info(\"Deleting older checkpoint [{}] due to args.save_total_limit\".format(checkpoint))\n",
    "        shutil.rmtree(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "N6rKb753kEpg"
   },
   "outputs": [],
   "source": [
    "# create dataset suitable for our model\n",
    "def construct_conv(row, tokenizer, eos = True):\n",
    "    flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "    conv = list(reversed([tokenizer.encode(x) + [tokenizer.eos_token_id] for x in row]))\n",
    "    conv = flatten(conv)\n",
    "    return conv\n",
    "\n",
    "class ConversationDataset(Dataset):\n",
    "    def __init__(self, tokenizer: PreTrainedTokenizer, args, df, block_size=512):\n",
    "\n",
    "        block_size = block_size - (tokenizer.model_max_length - tokenizer.max_len_single_sentence)\n",
    "\n",
    "        directory = args.cache_dir\n",
    "        cached_features_file = os.path.join(\n",
    "            directory, args.model_type + \"_cached_lm_\" + str(block_size)\n",
    "        )\n",
    "\n",
    "        if os.path.exists(cached_features_file) and not args.overwrite_cache:\n",
    "            logger.info(\"Loading features from cached file %s\", cached_features_file)\n",
    "            with open(cached_features_file, \"rb\") as handle:\n",
    "                self.examples = pickle.load(handle)\n",
    "        else:\n",
    "            logger.info(\"Creating features from dataset file at %s\", directory)\n",
    "\n",
    "            self.examples = []\n",
    "            for _, row in df.iterrows():\n",
    "                conv = construct_conv(row, tokenizer)\n",
    "                self.examples.append(conv)\n",
    "\n",
    "            logger.info(\"Saving features into cached file %s\", cached_features_file)\n",
    "            with open(cached_features_file, \"wb\") as handle:\n",
    "                pickle.dump(self.examples, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.examples)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        try :\n",
    "          return torch.tensor(self.examples[item], dtype=torch.long)\n",
    "        except:\n",
    "          print(f'item error : {item}, {self.examples[item]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "Lkqxc1FUkLkL"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelWithLMHead, AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"/content/drive/Othercomputers/MacBookPro/chatbot/ko_dialogpt/pleon-tokenizer\")\n",
    "# model = AutoModelWithLMHead.from_pretrained(\"microsoft/DialoGPT-medium\")\n",
    "\n",
    "from transformers import BertTokenizerFast, GPT2LMHeadModel\n",
    "# tokenizer_gpt3 = BertTokenizerFast.from_pretrained(\"kykim/gpt3-kor-small_based_on_gpt2\")\n",
    "# input_ids = tokenizer_gpt3.encode(\"text to tokenize\")[1:]  # remove cls token\n",
    "# model_gpt3 = GPT2LMHeadModel.from_pretrained(\"kykim/gpt3-kor-small_based_on_gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "TVAh1ehdkYwl"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Fine-tuning the library models for language modeling on a text file (GPT, GPT-2, BERT, RoBERTa).\n",
    "GPT and GPT-2 are fine-tuned using a causal language modeling (CLM) loss while BERT and RoBERTa are fine-tuned\n",
    "using a masked language modeling (MLM) loss.\n",
    "\"\"\"\n",
    "\n",
    "# Configs\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "MODEL_CONFIG_CLASSES = list(MODEL_WITH_LM_HEAD_MAPPING.keys())\n",
    "MODEL_TYPES = tuple(conf.model_type for conf in MODEL_CONFIG_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "7k1RKIwnkcca"
   },
   "outputs": [],
   "source": [
    "# Args to allow for easy convertion of python script to notebook\n",
    "class Args():\n",
    "    def __init__(self):\n",
    "        self.output_dir = '/home/hyeokiki/Desktop/ko_dialogpt'\n",
    "        self.model_type = 'gpt2'\n",
    "        # self.model_name_or_path = 'microsoft/DialoGPT-small'\n",
    "        self.model_name_or_path = 'beomi/kykim-gpt3-kor-small_based_on_gpt2'\n",
    "        # self.config_name = 'microsoft/DialoGPT-small'\n",
    "        self.config_name = 'beomi/kykim-gpt3-kor-small_based_on_gpt2'\n",
    "        # self.tokenizer_name = '/content/drive/Othercomputers/MacBookPro/chatbot/ko_dialogpt/pleon-tokenizer'\n",
    "        self.tokenizer_name = 'beomi/kykim-gpt3-kor-small_based_on_gpt2'\n",
    "        # self.cache_dir = '/content/drive/Othercomputers/MacBookPro/chatbot/dialogpt_small/cached'\n",
    "        self.cache_dir = 'cached'\n",
    "\n",
    "        self.block_size = 512\n",
    "        self.do_train = True\n",
    "        self.do_eval = True\n",
    "        self.evaluate_during_training = False\n",
    "        self.per_gpu_train_batch_size = 4\n",
    "        self.per_gpu_eval_batch_size = 4\n",
    "        self.gradient_accumulation_steps = 1\n",
    "        self.learning_rate = 5e-5\n",
    "        self.weight_decay = 0.0\n",
    "        self.adam_epsilon = 1e-8\n",
    "        self.max_grad_norm = 1.0\n",
    "        self.num_train_epochs = 32\n",
    "        self.max_steps = -1\n",
    "        self.warmup_steps = 0\n",
    "        self.logging_steps = 1000\n",
    "        self.save_steps = 100000 #원래 3500\n",
    "        self.save_total_limit = None\n",
    "        self.eval_all_checkpoints = False\n",
    "        self.no_cuda = False\n",
    "        self.overwrite_output_dir = True\n",
    "        self.overwrite_cache = True\n",
    "        self.should_continue = True\n",
    "        self.seed = 42\n",
    "        self.local_rank = -1\n",
    "        self.fp16 = False\n",
    "        self.fp16_opt_level = 'O1'\n",
    "\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "JHBIIAjWkxio"
   },
   "outputs": [],
   "source": [
    "def train(args, train_dataset, model: PreTrainedModel, tokenizer: PreTrainedTokenizer) -> Tuple[int, float]:\n",
    "    \"\"\" Train the model \"\"\"\n",
    "    if args.local_rank in [-1, 0]:\n",
    "        tb_writer = SummaryWriter()\n",
    "\n",
    "    args.train_batch_size = args.per_gpu_train_batch_size * max(1, args.n_gpu)\n",
    "\n",
    "\n",
    "    def collate(examples: List[torch.Tensor]):\n",
    "        if tokenizer._pad_token is None:\n",
    "            return pad_sequence(examples, batch_first=True)\n",
    "        return pad_sequence(examples, batch_first=True, padding_value=tokenizer.pad_token_id)\n",
    "\n",
    "    train_sampler = RandomSampler(train_dataset) if args.local_rank == -1 else DistributedSampler(train_dataset)\n",
    "    train_dataloader = DataLoader(\n",
    "        train_dataset, sampler=train_sampler, batch_size=args.train_batch_size, collate_fn=collate, drop_last = True\n",
    "    )\n",
    "\n",
    "    if args.max_steps > 0:\n",
    "        t_total = args.max_steps\n",
    "        args.num_train_epochs = args.max_steps // (len(train_dataloader) // args.gradient_accumulation_steps) + 1\n",
    "    else:\n",
    "        t_total = len(train_dataloader) // args.gradient_accumulation_steps * args.num_train_epochs\n",
    "\n",
    "    model = model.module if hasattr(model, \"module\") else model  # Take care of distributed/parallel training\n",
    "    model.resize_token_embeddings(len(tokenizer))\n",
    "    # add_special_tokens_(model, tokenizer)\n",
    "\n",
    "\n",
    "    # Prepare optimizer and schedule (linear warmup and decay)\n",
    "    no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "    optimizer_grouped_parameters = [\n",
    "        {\n",
    "            \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "            \"weight_decay\": args.weight_decay,\n",
    "        },\n",
    "        {\"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], \"weight_decay\": 0.0},\n",
    "    ]\n",
    "    optimizer = AdamW(optimizer_grouped_parameters, lr=args.learning_rate, eps=args.adam_epsilon)\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer, num_warmup_steps=args.warmup_steps, num_training_steps=t_total\n",
    "    )\n",
    "\n",
    "    # Check if saved optimizer or scheduler states exist\n",
    "    if (\n",
    "        args.model_name_or_path\n",
    "        and os.path.isfile(os.path.join(args.model_name_or_path, \"optimizer.pt\"))\n",
    "        and os.path.isfile(os.path.join(args.model_name_or_path, \"scheduler.pt\"))\n",
    "    ):\n",
    "        # Load in optimizer and scheduler states\n",
    "        optimizer.load_state_dict(torch.load(os.path.join(args.model_name_or_path, \"optimizer.pt\")))\n",
    "        scheduler.load_state_dict(torch.load(os.path.join(args.model_name_or_path, \"scheduler.pt\")))\n",
    "\n",
    "    if args.fp16:\n",
    "        try:\n",
    "            from apex import amp\n",
    "        except ImportError:\n",
    "            raise ImportError(\"Please install apex from https://www.github.com/nvidia/apex to use fp16 training.\")\n",
    "        model, optimizer = amp.initialize(model, optimizer, opt_level=args.fp16_opt_level)\n",
    "\n",
    "    # multi-gpu training (should be after apex fp16 initialization)\n",
    "    if args.n_gpu > 1:\n",
    "        model = torch.nn.DataParallel(model)\n",
    "\n",
    "    # Distributed training (should be after apex fp16 initialization)\n",
    "    if args.local_rank != -1:\n",
    "        model = torch.nn.parallel.DistributedDataParallel(\n",
    "            model, device_ids=[args.local_rank], output_device=args.local_rank, find_unused_parameters=True\n",
    "        )\n",
    "\n",
    "    # Train!\n",
    "    logger.info(\"***** Running training *****\")\n",
    "    logger.info(\"  Num examples = %d\", len(train_dataset))\n",
    "    logger.info(\"  Num Epochs = %d\", args.num_train_epochs)\n",
    "    logger.info(\"  Instantaneous batch size per GPU = %d\", args.per_gpu_train_batch_size)\n",
    "    logger.info(\n",
    "        \"  Total train batch size (w. parallel, distributed & accumulation) = %d\",\n",
    "        args.train_batch_size\n",
    "        * args.gradient_accumulation_steps\n",
    "        * (torch.distributed.get_world_size() if args.local_rank != -1 else 1),\n",
    "    )\n",
    "    logger.info(\"  Gradient Accumulation steps = %d\", args.gradient_accumulation_steps)\n",
    "    logger.info(\"  Total optimization steps = %d\", t_total)\n",
    "\n",
    "    global_step = 0\n",
    "    epochs_trained = 0\n",
    "    steps_trained_in_current_epoch = 0\n",
    "    # Check if continuing training from a checkpoint\n",
    "    if args.model_name_or_path and os.path.exists(args.model_name_or_path):\n",
    "        try:\n",
    "            # set global_step to gobal_step of last saved checkpoint from model path\n",
    "            checkpoint_suffix = args.model_name_or_path.split(\"-\")[-1].split(\"/\")[0]\n",
    "            global_step = int(checkpoint_suffix)\n",
    "            epochs_trained = global_step // (len(train_dataloader) // args.gradient_accumulation_steps)\n",
    "            steps_trained_in_current_epoch = global_step % (len(train_dataloader) // args.gradient_accumulation_steps)\n",
    "\n",
    "            logger.info(\"  Continuing training from checkpoint, will skip to saved global_step\")\n",
    "            logger.info(\"  Continuing training from epoch %d\", epochs_trained)\n",
    "            logger.info(\"  Continuing training from global step %d\", global_step)\n",
    "            logger.info(\"  Will skip the first %d steps in the first epoch\", steps_trained_in_current_epoch)\n",
    "        except ValueError:\n",
    "            logger.info(\"  Starting fine-tuning.\")\n",
    "\n",
    "    tr_loss, logging_loss = 0.0, 0.0\n",
    "\n",
    "    model.zero_grad()\n",
    "    train_iterator = trange(\n",
    "        epochs_trained, int(args.num_train_epochs), desc=\"Epoch\", disable=args.local_rank not in [-1, 0]\n",
    "    )\n",
    "    set_seed(args)  # Added here for reproducibility\n",
    "    for _ in train_iterator:\n",
    "        epoch_iterator = tqdm(train_dataloader, desc=\"Iteration\", disable=args.local_rank not in [-1, 0])\n",
    "        for step, batch in enumerate(epoch_iterator):\n",
    "\n",
    "            # Skip past any already trained steps if resuming training\n",
    "            if steps_trained_in_current_epoch > 0:\n",
    "                steps_trained_in_current_epoch -= 1\n",
    "                continue\n",
    "\n",
    "            inputs, labels = (batch, batch)\n",
    "            if inputs.shape[1] > 1024: continue\n",
    "            inputs = inputs.to(args.device)\n",
    "            labels = labels.to(args.device)\n",
    "            model.train()\n",
    "            outputs = model(inputs, labels=labels)\n",
    "            loss = outputs[0]  # model outputs are always tuple in transformers (see doc)\n",
    "\n",
    "            if args.n_gpu > 1:\n",
    "                loss = loss.mean()  # mean() to average on multi-gpu parallel training\n",
    "            if args.gradient_accumulation_steps > 1:\n",
    "                loss = loss / args.gradient_accumulation_steps\n",
    "\n",
    "            if args.fp16:\n",
    "                with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "                    scaled_loss.backward()\n",
    "            else:\n",
    "                loss.backward()\n",
    "\n",
    "            tr_loss += loss.item()\n",
    "            if (step + 1) % args.gradient_accumulation_steps == 0:\n",
    "                if args.fp16:\n",
    "                    torch.nn.utils.clip_grad_norm_(amp.master_params(optimizer), args.max_grad_norm)\n",
    "                else:\n",
    "                    torch.nn.utils.clip_grad_norm_(model.parameters(), args.max_grad_norm)\n",
    "                optimizer.step()\n",
    "                scheduler.step()  # Update learning rate schedule\n",
    "                model.zero_grad()\n",
    "                global_step += 1\n",
    "\n",
    "                if args.local_rank in [-1, 0] and args.logging_steps > 0 and global_step % args.logging_steps == 0:\n",
    "                    # Log metrics\n",
    "                    if (\n",
    "                        args.local_rank == -1 and args.evaluate_during_training\n",
    "                    ):  # Only evaluate when single GPU otherwise metrics may not average well\n",
    "                        results = evaluate(args, model, tokenizer)\n",
    "                        for key, value in results.items():\n",
    "                            tb_writer.add_scalar(\"eval_{}\".format(key), value, global_step)\n",
    "                    tb_writer.add_scalar(\"lr\", scheduler.get_lr()[0], global_step)\n",
    "                    tb_writer.add_scalar(\"loss\", (tr_loss - logging_loss) / args.logging_steps, global_step)\n",
    "                    logging_loss = tr_loss\n",
    "\n",
    "                if args.local_rank in [-1, 0] and args.save_steps > 0 and global_step % args.save_steps == 0:\n",
    "                    checkpoint_prefix = \"checkpoint\"\n",
    "                    # Save model checkpoint\n",
    "                    output_dir = os.path.join(args.output_dir, \"{}-{}\".format(checkpoint_prefix, global_step))\n",
    "                    os.makedirs(output_dir, exist_ok=True)\n",
    "                    model_to_save = (\n",
    "                        model.module if hasattr(model, \"module\") else model\n",
    "                    )  # Take care of distributed/parallel training\n",
    "                    model_to_save.save_pretrained(output_dir)\n",
    "                    tokenizer.save_pretrained(output_dir)\n",
    "\n",
    "                    torch.save(args, os.path.join(output_dir, \"training_args.bin\"))\n",
    "                    logger.info(\"Saving model checkpoint to %s\", output_dir)\n",
    "\n",
    "                    _rotate_checkpoints(args, checkpoint_prefix)\n",
    "\n",
    "                    torch.save(optimizer.state_dict(), os.path.join(output_dir, \"optimizer.pt\"))\n",
    "                    torch.save(scheduler.state_dict(), os.path.join(output_dir, \"scheduler.pt\"))\n",
    "                    logger.info(\"Saving optimizer and scheduler states to %s\", output_dir)\n",
    "\n",
    "            if args.max_steps > 0 and global_step > args.max_steps:\n",
    "                epoch_iterator.close()\n",
    "                break\n",
    "        if args.max_steps > 0 and global_step > args.max_steps:\n",
    "            train_iterator.close()\n",
    "            break\n",
    "\n",
    "    if args.local_rank in [-1, 0]:\n",
    "        tb_writer.close()\n",
    "\n",
    "    return global_step, tr_loss / global_step\n",
    "\n",
    "# Evaluation of some model\n",
    "\n",
    "def evaluate(args, model: PreTrainedModel, tokenizer: PreTrainedTokenizer, df_trn, df_val, prefix=\"\") -> Dict:\n",
    "    # Loop to handle MNLI double evaluation (matched, mis-matched)\n",
    "    eval_output_dir = args.output_dir\n",
    "\n",
    "    eval_dataset = load_and_cache_examples(args, tokenizer, df_trn, df_val, evaluate=True)\n",
    "    os.makedirs(eval_output_dir, exist_ok=True)\n",
    "    args.eval_batch_size = args.per_gpu_eval_batch_size * max(1, args.n_gpu)\n",
    "    # Note that DistributedSampler samples randomly\n",
    "\n",
    "    def collate(examples: List[torch.Tensor]):\n",
    "        if tokenizer._pad_token is None:\n",
    "            return pad_sequence(examples, batch_first=True)\n",
    "        return pad_sequence(examples, batch_first=True, padding_value=tokenizer.pad_token_id)\n",
    "\n",
    "    eval_sampler = SequentialSampler(eval_dataset)\n",
    "    eval_dataloader = DataLoader(\n",
    "        eval_dataset, sampler=eval_sampler, batch_size=args.eval_batch_size, collate_fn=collate, drop_last = True\n",
    "    )\n",
    "\n",
    "    # multi-gpu evaluate\n",
    "    if args.n_gpu > 1:\n",
    "        model = torch.nn.DataParallel(model)\n",
    "\n",
    "    # Eval!\n",
    "    logger.info(\"***** Running evaluation {} *****\".format(prefix))\n",
    "    logger.info(\"  Num examples = %d\", len(eval_dataset))\n",
    "    logger.info(\"  Batch size = %d\", args.eval_batch_size)\n",
    "    eval_loss = 0.0\n",
    "    nb_eval_steps = 0\n",
    "    model.eval()\n",
    "\n",
    "    for batch in tqdm(eval_dataloader, desc=\"Evaluating\"):\n",
    "        inputs, labels = (batch, batch)\n",
    "        inputs = inputs.to(args.device)\n",
    "        labels = labels.to(args.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(inputs, labels=labels)\n",
    "            lm_loss = outputs[0]\n",
    "            eval_loss += lm_loss.mean().item()\n",
    "        nb_eval_steps += 1\n",
    "\n",
    "    eval_loss = eval_loss / nb_eval_steps\n",
    "    perplexity = torch.exp(torch.tensor(eval_loss))\n",
    "\n",
    "    result = {\"perplexity\": perplexity}\n",
    "\n",
    "    output_eval_file = os.path.join(eval_output_dir, prefix, \"eval_results.txt\")\n",
    "    with open(output_eval_file, \"w\") as writer:\n",
    "        logger.info(\"***** Eval results {} *****\".format(prefix))\n",
    "        for key in sorted(result.keys()):\n",
    "            logger.info(\"  %s = %s\", key, str(result[key]))\n",
    "            writer.write(\"%s = %s\\n\" % (key, str(result[key])))\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "7dwztRsXlCfA"
   },
   "outputs": [],
   "source": [
    "# Main runner\n",
    "\n",
    "def main(df_trn, df_val):\n",
    "    args = Args()\n",
    "    \n",
    "    if args.should_continue:\n",
    "        sorted_checkpoints = _sorted_checkpoints(args)\n",
    "        if len(sorted_checkpoints) == 0:\n",
    "            shold_continue = False\n",
    "            # raise ValueError(\"Used --should_continue but no checkpoint was found in --output_dir.\")\n",
    "        else:\n",
    "            args.model_name_or_path = sorted_checkpoints[-1]\n",
    "\n",
    "    if (\n",
    "        os.path.exists(args.output_dir)\n",
    "        and os.listdir(args.output_dir)\n",
    "        and args.do_train\n",
    "        and not args.overwrite_output_dir\n",
    "        and not args.should_continue\n",
    "    ):\n",
    "        raise ValueError(\n",
    "            \"Output directory ({}) already exists and is not empty. Use --overwrite_output_dir to overcome.\".format(\n",
    "                args.output_dir\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # Setup CUDA, GPU & distributed training\n",
    "    device = torch.device(\"cuda\")\n",
    "    args.n_gpu = torch.cuda.device_count()\n",
    "    args.device = device\n",
    "\n",
    "    # Setup logging\n",
    "    logging.basicConfig(\n",
    "        format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n",
    "        datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "        level=logging.INFO if args.local_rank in [-1, 0] else logging.WARN,\n",
    "    )\n",
    "    logger.warning(\n",
    "        \"Process rank: %s, device: %s, n_gpu: %s, distributed training: %s, 16-bits training: %s\",\n",
    "        args.local_rank,\n",
    "        device,\n",
    "        args.n_gpu,\n",
    "        bool(args.local_rank != -1),\n",
    "        args.fp16,\n",
    "    )\n",
    "\n",
    "    # Set seed\n",
    "    set_seed(args)\n",
    "\n",
    "    # config = AutoConfig.from_pretrained(args.config_name)#, cache_dir=args.cache_dir)\n",
    "    config = AutoConfig.from_pretrained(args.config_name, cache_dir=args.cache_dir)\n",
    "    \n",
    "    print(args.tokenizer_name)\n",
    "    #tokenizer = AutoTokenizer.from_pretrained(args.tokenizer_name)#, cache_dir=args.cache_dir)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(args.tokenizer_name, cache_dir=args.cache_dir)\n",
    "\n",
    "    # tokenizer = BertTokenizerFast.from_pretrained(args.tokenizer_name, cache_dir=args.cache_dir)\n",
    "    tokenizer.add_special_tokens({\"eos_token\":\"[SEP]\",\n",
    "                               \"bos_token\":\"[SEP]\",})\n",
    "    \n",
    "    # model = AutoModelWithLMHead.from_pretrained(\n",
    "    #     args.model_name_or_path,\n",
    "    #     from_tf=False,\n",
    "    #     config=config,\n",
    "    # )\n",
    "    model = AutoModelWithLMHead.from_pretrained(\n",
    "        args.model_name_or_path,\n",
    "        from_tf=False,\n",
    "        config=config,\n",
    "        cache_dir=args.cache_dir,\n",
    "    )\n",
    "\n",
    "    # model = GPT2LMHeadModel.from_pretrained(\n",
    "    #     args.model_name_or_path,\n",
    "    #     from_tf=False,\n",
    "    #     config=config,\n",
    "    #     cache_dir=args.cache_dir,\n",
    "    # )\n",
    "    \n",
    "    model.to(args.device)\n",
    "    \n",
    "    logger.info(\"Training/evaluation parameters %s\", args)\n",
    "\n",
    "    # Training\n",
    "    if args.do_train:\n",
    "        train_dataset = load_and_cache_examples(args, tokenizer, df_trn, df_val, evaluate=False)\n",
    "\n",
    "        global_step, tr_loss = train(args, train_dataset, model, tokenizer)\n",
    "        logger.info(\" global_step = %s, average loss = %s\", global_step, tr_loss)\n",
    "\n",
    "    # Saving best-practices: if you use save_pretrained for the model and tokenizer, you can reload them using from_pretrained()\n",
    "    if args.do_train:\n",
    "        # Create output directory if needed\n",
    "        os.makedirs(args.output_dir, exist_ok=True)\n",
    "\n",
    "        logger.info(\"Saving model checkpoint to %s\", args.output_dir)\n",
    "        # Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
    "        # They can then be reloaded using `from_pretrained()`\n",
    "        model_to_save = (\n",
    "            model.module if hasattr(model, \"module\") else model\n",
    "        )  # Take care of distributed/parallel training\n",
    "        model_to_save.save_pretrained(args.output_dir)\n",
    "        tokenizer.save_pretrained(args.output_dir)\n",
    "\n",
    "        # Good practice: save your training arguments together with the trained model\n",
    "        torch.save(args, os.path.join(args.output_dir, \"training_args.bin\"))\n",
    "\n",
    "        # Load a trained model and vocabulary that you have fine-tuned\n",
    "        model = AutoModelWithLMHead.from_pretrained(args.output_dir)\n",
    "        # model = GPT2LMHeadModel.from_pretrained(args.output_dir)\n",
    "        tokenizer = AutoTokenizer.from_pretrained(args.output_dir)\n",
    "        tokenizer.add_special_tokens({\"eos_token\":\"[SEP]\",\n",
    "                               \"bos_token\":\"[SEP]\",})\n",
    "        # tokenizer = BertTokenizerFast.from_pretrained(args.output_dir)\n",
    "\n",
    "        # tokenizer = BertTokenizerFast.from_pretrained(\"kykim/gpt3-kor-small_based_on_gpt2\")\n",
    "        model.to(args.device)\n",
    "\n",
    "    # Evaluation\n",
    "    results = {}\n",
    "    if args.do_eval and args.local_rank in [-1, 0]:\n",
    "        checkpoints = [args.output_dir]\n",
    "        if args.eval_all_checkpoints:\n",
    "            checkpoints = list(\n",
    "                os.path.dirname(c) for c in sorted(glob.glob(args.output_dir + \"/**/\" + WEIGHTS_NAME, recursive=True))\n",
    "            )\n",
    "            logging.getLogger(\"transformers.modeling_utils\").setLevel(logging.WARN)  # Reduce logging\n",
    "        logger.info(\"Evaluate the following checkpoints: %s\", checkpoints)\n",
    "        for checkpoint in checkpoints:\n",
    "            global_step = checkpoint.split(\"-\")[-1] if len(checkpoints) > 1 else \"\"\n",
    "            prefix = checkpoint.split(\"/\")[-1] if checkpoint.find(\"checkpoint\") != -1 else \"\"\n",
    "\n",
    "            # model = GPT2LMHeadModel.from_pretrained(checkpoint)\n",
    "            model = AutoModelWithLMHead.from_pretrained(checkpoint)\n",
    "            model.to(args.device)\n",
    "            result = evaluate(args, model, tokenizer, df_trn, df_val, prefix=prefix)\n",
    "            result = dict((k + \"_{}\".format(global_step), v) for k, v in result.items())\n",
    "            results.update(result)\n",
    "             \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 406,
     "referenced_widgets": [
      "423b790bd81d4528b551dd8e81bea324",
      "c949090a349d4181a1d828f44690c020",
      "c69c5ce1fadb46d1aad910ee9661950b",
      "18c0bea2899642bc8801365131ddc6f3",
      "a55ee007238940e9a4a0567cf7fc919b",
      "f9e59712b42e4eebadf41f68fcf52e5c",
      "c1cd1e9c3cea4bf8a36c022b7aab6556",
      "a928c2a8b51344fe80c78381713fcf6c",
      "c93684ffa40a4e51905ccf40e0b9b7b6",
      "ea88e5adde7e4d4593a3e8e1da3114f5",
      "ae87018249834cb98578d617be256d24",
      "6a7d81ef4a914509961620801908faf0",
      "3374b5dbef524cdbb83979defa13ea4f",
      "86bc1785b83b4f1abc7c51e64dd5115b",
      "50764fe7a9034f91bbe7b9b911a2849e",
      "6a6bdca7652749b38e7804f840a61f8b",
      "8eda36dc9d04406d9ea2a49152ba21ea",
      "bf231b5549af4d578f04ca5b0858bc31",
      "fbc48c2ace034d0786da5562ed00aa55",
      "8a6ffc33276f46f09987ac1f8f9523cf",
      "b979262c1be64c36ae8c2e8cb7da59a1",
      "87677fa75b9a4ee28f90c03c19112fed",
      "b885a8f24da04cf9bae33df8cbe43176",
      "656bb384f9394acb9d2e155ad52d9b12",
      "24feaec90eed49b6b0d957cabf1749de",
      "6aa07b2108a445b1b8bc7e6aaedb2467",
      "e56a5d4c7dc945129e8c96415bf77a73",
      "560756b5096d4a1390360733e5e9eda6",
      "0cbaa6d9490e415f842c5cd64b09625c",
      "c086ba247411452c97d0b8bfa0d74bab",
      "b0a1523963274757a4331ba8902f6907",
      "f1c4b6e2b3144cd6a831d4b3ef7d060e",
      "bbc657e3f2f842e79e14cb4ad6b8d490",
      "d8f3da03e2864283930ef0bda7354f81",
      "42d250af0a2544a3a555520753025e60",
      "09a3175e2e6f4783bd8bb46de4034ea1",
      "bd4d83c40f9c47399503d910dd5486b8",
      "8521db2f47e14c90a45cc7e202a59e80",
      "53363bf77c8c4a1899ef2cc4c34a31ee",
      "3ab92cbc2b604c7fa79e431ccddd60de",
      "2cee073648b2464ea3fd6185531f3ef2",
      "79f198b4e1be4b5a8fadcd946b9ba0d6",
      "566927d13ca840a680b4671d2cc2493e",
      "13efb018403d4e22837cae5763093eef",
      "5e70ad143969446eaa0257b0993aca80",
      "45f02410a76347b7a21ecd32e43f6ffb",
      "cbb15dd99bf24a56bd8dad513cab1eb7",
      "a99ecd581b7145f78c108e8f4d1ae968",
      "ccb953f6319340289016ac8e47036b2e",
      "c00c62e603eb4c3d83c29694c75d574c",
      "2641be2c3b7c4c30b294a14480643781",
      "a2ecf3247432461f8fb54e8586494a44",
      "26016b1e0c324fd084d25ddd5099a723",
      "05b4cfd89c8147caa82f6c7718644925",
      "c161262f9932431aa534608231670bd0",
      "79f0c86cb9ab44d995f68dc297202195",
      "6d2fc475854744f387ed65aa5cd63b71",
      "f15d5fd1eddc4163b9e8f27b271fb031",
      "4d09ede97be947a1b463d46328ea7a06",
      "dede50e955bc403c9fed30be7e5892ee",
      "6c345ad5598c4b3ebea43602aa1898f6",
      "75bb48cdf5904fac956b2fd3fb393290",
      "34e7148532d74aa2883fa8d1584dc194",
      "b81ffff750df4c59a1da200c404f3880",
      "84dbc55424194741b6eebdd8f8cb9471",
      "169d2c9178f445dda19a5212a9eba40c",
      "948f85bce8a44ef08fb7ab7c7072986b",
      "92e70550a0f840c496fe3f46d1f1d4f3",
      "61683895ca3348d380544c14e2364f45",
      "2d3c645a80b84eea86632dca2bbedc99",
      "c8198720345d4191a81cc9d8ba0ccb7b",
      "54520593234e44e2b43103ec54b13744",
      "baadaae68da747b792be1d237a5d4d48",
      "b7bce9d29ab842919540bef123047b62",
      "6db1ef82bd40415c9be26e0a631d80b6",
      "5df9fbf4670741669d47a0fbb5c257cd",
      "6d3b4464281244a195a07568574051f1"
     ]
    },
    "id": "IaHMemc8lMnB",
    "outputId": "32ab6574-5b77-4bae-c377-624f7dec4734",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/03/2022 16:53:59 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beomi/kykim-gpt3-kor-small_based_on_gpt2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c206e4426c79480caf2dc1794689cc5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/526M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/03/2022 16:54:50 - INFO - __main__ -   Training/evaluation parameters <__main__.Args object at 0x7fec1ece0040>\n",
      "11/03/2022 16:54:50 - INFO - __main__ -   Creating features from dataset file at cached\n",
      "11/03/2022 16:56:16 - INFO - __main__ -   Saving features into cached file cached/gpt2_cached_lm_510\n",
      "11/03/2022 16:56:16 - INFO - __main__ -   ***** Running training *****\n",
      "11/03/2022 16:56:16 - INFO - __main__ -     Num examples = 196193\n",
      "11/03/2022 16:56:16 - INFO - __main__ -     Num Epochs = 32\n",
      "11/03/2022 16:56:16 - INFO - __main__ -     Instantaneous batch size per GPU = 4\n",
      "11/03/2022 16:56:16 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "11/03/2022 16:56:16 - INFO - __main__ -     Gradient Accumulation steps = 1\n",
      "11/03/2022 16:56:16 - INFO - __main__ -     Total optimization steps = 1569536\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31dacf3ef0a54e518a9637a2e2391381",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "520be1255059450c9f44fffd5e8cd172",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/49048 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hyeokiki/anaconda3/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:249: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b11fff1fe664055af5209591aa745a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/49048 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7aa24b62c94497fb72c644c291b5f86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/49048 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/03/2022 19:00:27 - INFO - __main__ -   Saving model checkpoint to /home/hyeokiki/Desktop/ko_dialogpt/checkpoint-100000\n",
      "11/03/2022 19:00:28 - INFO - __main__ -   Saving optimizer and scheduler states to /home/hyeokiki/Desktop/ko_dialogpt/checkpoint-100000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c75f1ca1af4e4d1abe357b89dc2bab9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/49048 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63cffa65b5b54307aa7c181b288d02cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/49048 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/03/2022 21:05:24 - INFO - __main__ -   Saving model checkpoint to /home/hyeokiki/Desktop/ko_dialogpt/checkpoint-200000\n",
      "11/03/2022 21:05:25 - INFO - __main__ -   Saving optimizer and scheduler states to /home/hyeokiki/Desktop/ko_dialogpt/checkpoint-200000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcf455310b5c476aa7f68f05ddd41b92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/49048 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c402603741fd40eeab435af9b02ac640",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/49048 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/03/2022 23:10:07 - INFO - __main__ -   Saving model checkpoint to /home/hyeokiki/Desktop/ko_dialogpt/checkpoint-300000\n",
      "11/03/2022 23:10:08 - INFO - __main__ -   Saving optimizer and scheduler states to /home/hyeokiki/Desktop/ko_dialogpt/checkpoint-300000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4eb11b325bd84b3cb7f52cbc7e73b478",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/49048 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_19670/4290944384.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrn_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_19670/3155788612.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m(df_trn, df_val)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_and_cache_examples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_trn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0mglobal_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtr_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" global_step = %s, average loss = %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtr_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_19670/268469234.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(args, train_dataset, model, tokenizer)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1024\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "main(trn_df, val_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m--aK8UzntCX"
   },
   "source": [
    "beomi/kykim-gpt3-kor-small_based_on_gpt2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rLLVOiGR2cwK"
   },
   "outputs": [],
   "source": [
    "tokenizer.add_special_tokens({\"eos_token\":\"[SEP]\",\n",
    "                               \"bos_token\":\"[SEP]\",})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xQr7tjIX3sAg"
   },
   "outputs": [],
   "source": [
    "tokenizer1.bos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gb45sItNkCgZ"
   },
   "outputs": [],
   "source": [
    "temp_df = trn_df.apply(lambda x: tokenizer.encode(' '.join(list(x))), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T28rryPvnABz"
   },
   "outputs": [],
   "source": [
    "temp_df[temp_df.apply(lambda x: len(x)) ==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h0yBTCV8nRQW"
   },
   "outputs": [],
   "source": [
    "construct_conv1(trn_df.loc[295357], tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jr5whIIkzUoY"
   },
   "outputs": [],
   "source": [
    "trn_df.loc[295357]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iR3kC7NpyRj5"
   },
   "outputs": [],
   "source": [
    "def construct_conv1(row, tokenizer, eos = True):\n",
    "    flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "    conv = list(reversed([[x] + [tokenizer.eos_token_id] for x in row]))\n",
    "    conv = flatten(conv)\n",
    "    return conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FGh6_AinzK3N"
   },
   "outputs": [],
   "source": [
    "for i, row in trn_df.iterrows():\n",
    "  if i != 295357:\n",
    "    continue\n",
    "  print(i, row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mDfURweBzXfr"
   },
   "outputs": [],
   "source": [
    "print(tokenizer.all_special_ids)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPpfejExZe7nBEZx8JDvlYO",
   "collapsed_sections": [],
   "machine_shape": "hm",
   "mount_file_id": "1I49N_wzByTyHetnxW2N3TFXmRstl9x0c",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "05b4cfd89c8147caa82f6c7718644925": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "09a3175e2e6f4783bd8bb46de4034ea1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2cee073648b2464ea3fd6185531f3ef2",
      "max": 12,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_79f198b4e1be4b5a8fadcd946b9ba0d6",
      "value": 2
     }
    },
    "0cbaa6d9490e415f842c5cd64b09625c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "13efb018403d4e22837cae5763093eef": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "169d2c9178f445dda19a5212a9eba40c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "18c0bea2899642bc8801365131ddc6f3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ea88e5adde7e4d4593a3e8e1da3114f5",
      "placeholder": "​",
      "style": "IPY_MODEL_ae87018249834cb98578d617be256d24",
      "value": " 620/620 [00:00&lt;00:00, 13.0kB/s]"
     }
    },
    "24feaec90eed49b6b0d957cabf1749de": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c086ba247411452c97d0b8bfa0d74bab",
      "max": 344259,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b0a1523963274757a4331ba8902f6907",
      "value": 344259
     }
    },
    "26016b1e0c324fd084d25ddd5099a723": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2641be2c3b7c4c30b294a14480643781": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2cee073648b2464ea3fd6185531f3ef2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2d3c645a80b84eea86632dca2bbedc99": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5df9fbf4670741669d47a0fbb5c257cd",
      "placeholder": "​",
      "style": "IPY_MODEL_6d3b4464281244a195a07568574051f1",
      "value": " 42/109480 [00:09&lt;6:30:38,  4.67it/s]"
     }
    },
    "3374b5dbef524cdbb83979defa13ea4f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8eda36dc9d04406d9ea2a49152ba21ea",
      "placeholder": "​",
      "style": "IPY_MODEL_bf231b5549af4d578f04ca5b0858bc31",
      "value": "Downloading: 100%"
     }
    },
    "34e7148532d74aa2883fa8d1584dc194": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3ab92cbc2b604c7fa79e431ccddd60de": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "423b790bd81d4528b551dd8e81bea324": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c949090a349d4181a1d828f44690c020",
       "IPY_MODEL_c69c5ce1fadb46d1aad910ee9661950b",
       "IPY_MODEL_18c0bea2899642bc8801365131ddc6f3"
      ],
      "layout": "IPY_MODEL_a55ee007238940e9a4a0567cf7fc919b"
     }
    },
    "42d250af0a2544a3a555520753025e60": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_53363bf77c8c4a1899ef2cc4c34a31ee",
      "placeholder": "​",
      "style": "IPY_MODEL_3ab92cbc2b604c7fa79e431ccddd60de",
      "value": "Epoch:  17%"
     }
    },
    "45f02410a76347b7a21ecd32e43f6ffb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c00c62e603eb4c3d83c29694c75d574c",
      "placeholder": "​",
      "style": "IPY_MODEL_2641be2c3b7c4c30b294a14480643781",
      "value": "Iteration: 100%"
     }
    },
    "4d09ede97be947a1b463d46328ea7a06": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_84dbc55424194741b6eebdd8f8cb9471",
      "placeholder": "​",
      "style": "IPY_MODEL_169d2c9178f445dda19a5212a9eba40c",
      "value": " 109480/109480 [6:41:42&lt;00:00,  4.34it/s]"
     }
    },
    "50764fe7a9034f91bbe7b9b911a2849e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b979262c1be64c36ae8c2e8cb7da59a1",
      "placeholder": "​",
      "style": "IPY_MODEL_87677fa75b9a4ee28f90c03c19112fed",
      "value": " 119/119 [00:00&lt;00:00, 4.20kB/s]"
     }
    },
    "53363bf77c8c4a1899ef2cc4c34a31ee": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "54520593234e44e2b43103ec54b13744": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "560756b5096d4a1390360733e5e9eda6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "566927d13ca840a680b4671d2cc2493e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5df9fbf4670741669d47a0fbb5c257cd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5e70ad143969446eaa0257b0993aca80": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_45f02410a76347b7a21ecd32e43f6ffb",
       "IPY_MODEL_cbb15dd99bf24a56bd8dad513cab1eb7",
       "IPY_MODEL_a99ecd581b7145f78c108e8f4d1ae968"
      ],
      "layout": "IPY_MODEL_ccb953f6319340289016ac8e47036b2e"
     }
    },
    "61683895ca3348d380544c14e2364f45": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b7bce9d29ab842919540bef123047b62",
      "max": 109480,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6db1ef82bd40415c9be26e0a631d80b6",
      "value": 42
     }
    },
    "656bb384f9394acb9d2e155ad52d9b12": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_560756b5096d4a1390360733e5e9eda6",
      "placeholder": "​",
      "style": "IPY_MODEL_0cbaa6d9490e415f842c5cd64b09625c",
      "value": "Downloading: 100%"
     }
    },
    "6a6bdca7652749b38e7804f840a61f8b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6a7d81ef4a914509961620801908faf0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3374b5dbef524cdbb83979defa13ea4f",
       "IPY_MODEL_86bc1785b83b4f1abc7c51e64dd5115b",
       "IPY_MODEL_50764fe7a9034f91bbe7b9b911a2849e"
      ],
      "layout": "IPY_MODEL_6a6bdca7652749b38e7804f840a61f8b"
     }
    },
    "6aa07b2108a445b1b8bc7e6aaedb2467": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f1c4b6e2b3144cd6a831d4b3ef7d060e",
      "placeholder": "​",
      "style": "IPY_MODEL_bbc657e3f2f842e79e14cb4ad6b8d490",
      "value": " 344k/344k [00:00&lt;00:00, 3.47MB/s]"
     }
    },
    "6c345ad5598c4b3ebea43602aa1898f6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6d2fc475854744f387ed65aa5cd63b71": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6c345ad5598c4b3ebea43602aa1898f6",
      "placeholder": "​",
      "style": "IPY_MODEL_75bb48cdf5904fac956b2fd3fb393290",
      "value": "Iteration: 100%"
     }
    },
    "6d3b4464281244a195a07568574051f1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6db1ef82bd40415c9be26e0a631d80b6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "75bb48cdf5904fac956b2fd3fb393290": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "79f0c86cb9ab44d995f68dc297202195": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6d2fc475854744f387ed65aa5cd63b71",
       "IPY_MODEL_f15d5fd1eddc4163b9e8f27b271fb031",
       "IPY_MODEL_4d09ede97be947a1b463d46328ea7a06"
      ],
      "layout": "IPY_MODEL_dede50e955bc403c9fed30be7e5892ee"
     }
    },
    "79f198b4e1be4b5a8fadcd946b9ba0d6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "84dbc55424194741b6eebdd8f8cb9471": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8521db2f47e14c90a45cc7e202a59e80": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "86bc1785b83b4f1abc7c51e64dd5115b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fbc48c2ace034d0786da5562ed00aa55",
      "max": 119,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8a6ffc33276f46f09987ac1f8f9523cf",
      "value": 119
     }
    },
    "87677fa75b9a4ee28f90c03c19112fed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8a6ffc33276f46f09987ac1f8f9523cf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8eda36dc9d04406d9ea2a49152ba21ea": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "92e70550a0f840c496fe3f46d1f1d4f3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_54520593234e44e2b43103ec54b13744",
      "placeholder": "​",
      "style": "IPY_MODEL_baadaae68da747b792be1d237a5d4d48",
      "value": "Iteration:   0%"
     }
    },
    "948f85bce8a44ef08fb7ab7c7072986b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_92e70550a0f840c496fe3f46d1f1d4f3",
       "IPY_MODEL_61683895ca3348d380544c14e2364f45",
       "IPY_MODEL_2d3c645a80b84eea86632dca2bbedc99"
      ],
      "layout": "IPY_MODEL_c8198720345d4191a81cc9d8ba0ccb7b"
     }
    },
    "a2ecf3247432461f8fb54e8586494a44": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a55ee007238940e9a4a0567cf7fc919b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a928c2a8b51344fe80c78381713fcf6c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a99ecd581b7145f78c108e8f4d1ae968": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_05b4cfd89c8147caa82f6c7718644925",
      "placeholder": "​",
      "style": "IPY_MODEL_c161262f9932431aa534608231670bd0",
      "value": " 109480/109480 [2:53:46&lt;00:00,  4.62it/s]"
     }
    },
    "ae87018249834cb98578d617be256d24": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b0a1523963274757a4331ba8902f6907": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b7bce9d29ab842919540bef123047b62": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b81ffff750df4c59a1da200c404f3880": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b885a8f24da04cf9bae33df8cbe43176": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_656bb384f9394acb9d2e155ad52d9b12",
       "IPY_MODEL_24feaec90eed49b6b0d957cabf1749de",
       "IPY_MODEL_6aa07b2108a445b1b8bc7e6aaedb2467"
      ],
      "layout": "IPY_MODEL_e56a5d4c7dc945129e8c96415bf77a73"
     }
    },
    "b979262c1be64c36ae8c2e8cb7da59a1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "baadaae68da747b792be1d237a5d4d48": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bbc657e3f2f842e79e14cb4ad6b8d490": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bd4d83c40f9c47399503d910dd5486b8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_566927d13ca840a680b4671d2cc2493e",
      "placeholder": "​",
      "style": "IPY_MODEL_13efb018403d4e22837cae5763093eef",
      "value": " 2/12 [9:35:28&lt;51:18:30, 18471.05s/it]"
     }
    },
    "bf231b5549af4d578f04ca5b0858bc31": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c00c62e603eb4c3d83c29694c75d574c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c086ba247411452c97d0b8bfa0d74bab": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c161262f9932431aa534608231670bd0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c1cd1e9c3cea4bf8a36c022b7aab6556": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c69c5ce1fadb46d1aad910ee9661950b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a928c2a8b51344fe80c78381713fcf6c",
      "max": 620,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c93684ffa40a4e51905ccf40e0b9b7b6",
      "value": 620
     }
    },
    "c8198720345d4191a81cc9d8ba0ccb7b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c93684ffa40a4e51905ccf40e0b9b7b6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c949090a349d4181a1d828f44690c020": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f9e59712b42e4eebadf41f68fcf52e5c",
      "placeholder": "​",
      "style": "IPY_MODEL_c1cd1e9c3cea4bf8a36c022b7aab6556",
      "value": "Downloading: 100%"
     }
    },
    "cbb15dd99bf24a56bd8dad513cab1eb7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a2ecf3247432461f8fb54e8586494a44",
      "max": 109480,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_26016b1e0c324fd084d25ddd5099a723",
      "value": 109480
     }
    },
    "ccb953f6319340289016ac8e47036b2e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d8f3da03e2864283930ef0bda7354f81": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_42d250af0a2544a3a555520753025e60",
       "IPY_MODEL_09a3175e2e6f4783bd8bb46de4034ea1",
       "IPY_MODEL_bd4d83c40f9c47399503d910dd5486b8"
      ],
      "layout": "IPY_MODEL_8521db2f47e14c90a45cc7e202a59e80"
     }
    },
    "dede50e955bc403c9fed30be7e5892ee": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e56a5d4c7dc945129e8c96415bf77a73": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ea88e5adde7e4d4593a3e8e1da3114f5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f15d5fd1eddc4163b9e8f27b271fb031": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_34e7148532d74aa2883fa8d1584dc194",
      "max": 109480,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b81ffff750df4c59a1da200c404f3880",
      "value": 109480
     }
    },
    "f1c4b6e2b3144cd6a831d4b3ef7d060e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f9e59712b42e4eebadf41f68fcf52e5c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fbc48c2ace034d0786da5562ed00aa55": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
